{"cells":[{"cell_type":"markdown","metadata":{"papermill":{"duration":0.008914,"end_time":"2022-08-29T06:34:27.892052","exception":false,"start_time":"2022-08-29T06:34:27.883138","status":"completed"},"pycharm":{"name":"#%% md\n"},"tags":[]},"source":["<div class=\"alert alert-block alert-success\" style=\"font-size:30px\">\n","ü¶¥ [inference] Pytorch EfficientNet-v2 single model LB:0.49; 5-fold ensemble LB:0.47 ü¶¥\n","</div>\n","\n","<div class=\"alert alert-block alert-danger\" style=\"text-align:center; font-size:20px;\">\n","    ‚ù§Ô∏è Dont forget to ‚ñ≤upvote‚ñ≤ if you find this notebook usefull!  ‚ù§Ô∏è\n","</div>\n","\n","<div class=\"alert alert-block alert-info\">\n","    üìå Note, that this is the inference part. Refer to the training part for more details: <a href=\"https://www.kaggle.com/vslaykovsky/train-pytorch-effnetv2-baseline-cv-0-49\">[train] PyTorch-EffNetV2 baseline CV:0.49</a>\n","</div>\n","\n","This is a bare-bones PyTorch implementation of EfficientNet-v2 based classifier. This is a simple baseline implementation that can be iteratively improved.\n","\n","<img src=\"https://images2.imgbox.com/cd/58/AeY81v9Y_o.png\" alt=\"image host\"/>\n","\n","\n","Here is a high level explanation of the **inference** flow:\n","1. Images are loaded from test folder and transformed to `3x384x384` tensors using the same transformations used in training.\n","2. Images are passed to an ensemble of trained `EfficientNet_V2_S`-based multi-label classifiers. The classifier produces probabilities of fractures and probabilities of existence of certain vertebrae in each slice. Note that you can also use a single model `effnetv2` which is trained on all folds and likely performs slightly better than any of the fold-models.\n","3. We use a non-parametric model to combine predictions of base models:\n","    * For each StudyInstanceUID we first aggregate predictions for each of C1-C7 vertebrae by weighted averaging fracture predictions. Probabilities of vertebrae are used as weights. Example: if we are uncertain that C3 is in the slice (`C3_effnet_vert==0.1`), but we somehow predict high probability of C3 being fractured (`C3_effnet_frac==0.9`), we add it to the final aggregate with low weight `0.9 * 0.1 == 0.09`\n","    * We use a simple probability formula to derive `patient_overall` fracture probability. `patient_overall` is a probability of any vertebrae being fractured. It is equal to `1-no-vertebrae-are-fractured`. Under assumption of independence of vertebrae fractures we can derive the following simple equation: $P_{\\text{patient_overall}}=1-\\prod_i{[1-C_i]}$\n"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.005122,"end_time":"2022-08-29T06:34:27.903265","exception":false,"start_time":"2022-08-29T06:34:27.898143","status":"completed"},"pycharm":{"name":"#%% md\n"},"tags":[]},"source":["<div class=\"alert alert-block alert-success\" style=\"font-size:25px\">\n","ü¶¥ 1. Imports, constants and dependencies ü¶¥\n","</div>"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2022-09-07T02:31:51.976080Z","iopub.status.busy":"2022-09-07T02:31:51.974858Z","iopub.status.idle":"2022-09-07T02:33:41.983232Z","shell.execute_reply":"2022-09-07T02:33:41.982066Z","shell.execute_reply.started":"2022-09-07T02:31:51.975945Z"},"papermill":{"duration":110.198147,"end_time":"2022-08-29T06:36:18.107292","exception":false,"start_time":"2022-08-29T06:34:27.909145","status":"completed"},"pycharm":{"name":"#%%\n"},"tags":[],"trusted":true},"outputs":[],"source":["try:\n","    import pylibjpeg\n","except:\n","    # Offline dependencies:\n","    !mkdir -p /root/.cache/torch/hub/checkpoints/\n","    !cp ../input/rsna-2022-whl/efficientnet_v2_s-dd5fe13b.pth  /root/.cache/torch/hub/checkpoints/\n","\n","    !pip install /kaggle/input/rsna-2022-whl/{pydicom-2.3.0-py3-none-any.whl,pylibjpeg-1.4.0-py3-none-any.whl,python_gdcm-3.0.15-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl}\n","    !pip install /kaggle/input/rsna-2022-whl/{torch-1.12.1-cp37-cp37m-manylinux1_x86_64.whl,torchvision-0.13.1-cp37-cp37m-manylinux1_x86_64.whl}"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2022-09-07T02:26:31.605951Z","iopub.status.busy":"2022-09-07T02:26:31.604720Z","iopub.status.idle":"2022-09-07T02:26:31.617487Z","shell.execute_reply":"2022-09-07T02:26:31.616516Z","shell.execute_reply.started":"2022-09-07T02:26:31.605909Z"},"papermill":{"duration":2.969425,"end_time":"2022-08-29T06:36:21.083846","exception":false,"start_time":"2022-08-29T06:36:18.114421","status":"completed"},"pycharm":{"name":"#%%\n"},"tags":[],"trusted":true},"outputs":[],"source":["import gc\n","import glob\n","import os\n","import re\n","\n","import cv2\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import pydicom as dicom\n","import torch\n","import torchvision as tv\n","from sklearn.model_selection import GroupKFold\n","from torch.cuda.amp import GradScaler, autocast\n","from torchvision.models.feature_extraction import create_feature_extractor\n","from tqdm.notebook import tqdm\n","\n","import wandb\n","\n","pd.set_option('display.max_rows', 1000)\n","pd.set_option('display.max_columns', 1000)\n","plt.rcParams['figure.figsize'] = (20, 5)\n","\n","\n","# Effnet\n","WEIGHTS = tv.models.efficientnet.EfficientNet_V2_S_Weights.DEFAULT\n","RSNA_2022_PATH = '../input/rsna-2022-cervical-spine-fracture-detection'\n","TRAIN_IMAGES_PATH = f'{RSNA_2022_PATH}/train_images'\n","TEST_IMAGES_PATH = f'{RSNA_2022_PATH}/test_images'\n","EFFNET_CHECKPOINTS_PATH = '../input/rsna-2022-base-effnetv2'\n","\n","# MODEL_NAMES = [f'effnetv2']\n","\n","# This notebook supports ensembles and single model predictions. Uncomment to switch to ensemble prediction:\n","MODEL_NAMES = [f'effnetv2-f{i}' for i in range(5)]\n","\n","# Common\n","FRAC_COLS = [f'C{i}_effnet_frac' for i in range(1, 8)]\n","VERT_COLS = [f'C{i}_effnet_vert' for i in range(1, 8)]\n","\n","try:\n","    from kaggle_secrets import UserSecretsClient\n","    IS_KAGGLE = True\n","except:\n","    IS_KAGGLE = False\n","\n","\n","# Switch to offline for submission\n","os.environ[\"WANDB_MODE\"] = \"offline\"\n","\n","if os.environ[\"WANDB_MODE\"] == \"online\":\n","    if IS_KAGGLE:\n","        os.environ['WANDB_API_KEY'] = UserSecretsClient().get_secret(\"WANDB_API_KEY\")\n","\n","if not IS_KAGGLE:\n","    print('Running locally')\n","    RSNA_2022_PATH = '/mnt/rsna2022'\n","    TRAIN_IMAGES_PATH = '/mnt/rsna2022/train_images'\n","    TEST_IMAGES_PATH = '/mnt/rsna2022/test_images'\n","    METADATA_PATH = '/home/vslaykovsky/Downloads/'\n","    EFFNET_CHECKPOINTS_PATH = 'frac_checkpoints'\n","    os.environ['WANDB_API_KEY'] = 'yourkeyhere'\n","\n","\n","DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n","if DEVICE == 'cuda':\n","    BATCH_SIZE = 32\n","else:\n","    BATCH_SIZE = 2"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.006232,"end_time":"2022-08-29T06:36:21.096794","exception":false,"start_time":"2022-08-29T06:36:21.090562","status":"completed"},"pycharm":{"name":"#%% md\n"},"tags":[]},"source":["<div class=\"alert alert-block alert-success\" style=\"font-size:25px\">\n","    ü¶¥ 2. Loading train/eval/test dataframes ü¶¥\n","</div>\n","\n","1. Loading data from competition dataset folder `../input/rsna-2022-cervical-spine-fracture-detection/test.csv`\n","2. Joining data with slice information collected from test image folders `../input/rsna-2022-cervical-spine-fracture-detection/test_images/*/*`"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-29T09:17:52.136413Z","iopub.status.busy":"2022-08-29T09:17:52.135494Z","iopub.status.idle":"2022-08-29T09:17:52.171429Z","shell.execute_reply":"2022-08-29T09:17:52.169761Z","shell.execute_reply.started":"2022-08-29T09:17:52.136371Z"},"papermill":{"duration":0.045491,"end_time":"2022-08-29T06:36:21.148473","exception":false,"start_time":"2022-08-29T06:36:21.102982","status":"completed"},"pycharm":{"name":"#%%\n"},"tags":[],"trusted":true},"outputs":[],"source":["def load_df_test():\n","    df_test = pd.read_csv(f'{RSNA_2022_PATH}/test.csv')\n","\n","    if df_test.iloc[0].row_id == '1.2.826.0.1.3680043.10197_C1':\n","        # test_images and test.csv are inconsistent in the dev dataset, fixing labels for the dev run.\n","        df_test = pd.DataFrame({\n","            \"row_id\": ['1.2.826.0.1.3680043.22327_C1', '1.2.826.0.1.3680043.25399_C1', '1.2.826.0.1.3680043.5876_C1'],\n","            \"StudyInstanceUID\": ['1.2.826.0.1.3680043.22327', '1.2.826.0.1.3680043.25399', '1.2.826.0.1.3680043.5876'],\n","            \"prediction_type\": [\"C1\", \"C1\", \"patient_overall\"]}\n","        )\n","    return df_test\n","\n","df_test = load_df_test()\n","df_test"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-29T09:17:52.175696Z","iopub.status.busy":"2022-08-29T09:17:52.175045Z","iopub.status.idle":"2022-08-29T09:17:52.21635Z","shell.execute_reply":"2022-08-29T09:17:52.215294Z","shell.execute_reply.started":"2022-08-29T09:17:52.175644Z"},"papermill":{"duration":0.145663,"end_time":"2022-08-29T06:36:21.302098","exception":false,"start_time":"2022-08-29T06:36:21.156435","status":"completed"},"pycharm":{"name":"#%%\n"},"tags":[],"trusted":true},"outputs":[],"source":["test_slices = glob.glob(f'{TEST_IMAGES_PATH}/*/*')\n","test_slices = [re.findall(f'{TEST_IMAGES_PATH}/(.*)/(.*).dcm', s)[0] for s in test_slices]\n","df_test_slices = pd.DataFrame(data=test_slices, columns=['StudyInstanceUID', 'Slice']).astype({'Slice': int}).sort_values(['StudyInstanceUID', 'Slice']).reset_index(drop=True)\n","df_test_slices"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.006754,"end_time":"2022-08-29T06:36:21.315661","exception":false,"start_time":"2022-08-29T06:36:21.308907","status":"completed"},"pycharm":{"name":"#%% md\n"},"tags":[]},"source":["<div class=\"alert alert-block alert-success\" style=\"font-size:25px\">\n","    ü¶¥ 3. Dataset class ü¶¥\n","</div>\n","\n","`EffnetDataSet` class returns images of individual slices. It uses a dataframe parameter `df` as a source of slices metadata to locate and load images from `path` folder. It accepts transforms parameter which we set to `WEIGHTS.transforms()`. This is a set of transforms used to pre-train the model on ImageNet dataset."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-29T09:17:52.218251Z","iopub.status.busy":"2022-08-29T09:17:52.2177Z","iopub.status.idle":"2022-08-29T09:17:52.858043Z","shell.execute_reply":"2022-08-29T09:17:52.856992Z","shell.execute_reply.started":"2022-08-29T09:17:52.218213Z"},"papermill":{"duration":0.619183,"end_time":"2022-08-29T06:36:21.941518","exception":false,"start_time":"2022-08-29T06:36:21.322335","status":"completed"},"pycharm":{"name":"#%%\n"},"tags":[],"trusted":true},"outputs":[],"source":["def load_dicom(path):\n","    \"\"\"\n","    This supports loading both regular and compressed JPEG images. \n","    See the first sell with `pip install` commands for the necessary dependencies\n","    \"\"\"\n","    img=dicom.dcmread(path)\n","    img.PhotometricInterpretation = 'YBR_FULL'\n","    data = img.pixel_array    \n","    data = data - np.min(data)\n","    if np.max(data) != 0:\n","        data = data / np.max(data)\n","    data=(data * 255).astype(np.uint8)\n","    return cv2.cvtColor(data, cv2.COLOR_GRAY2RGB), img\n","\n","\n","im, meta = load_dicom(f'{TRAIN_IMAGES_PATH}/1.2.826.0.1.3680043.10001/1.dcm')\n","plt.figure()\n","plt.imshow(im)\n","plt.title('regular image')\n","\n","im, meta = load_dicom(f'{TRAIN_IMAGES_PATH}/1.2.826.0.1.3680043.10014/1.dcm')\n","plt.figure()\n","plt.imshow(im)\n","plt.title('jpeg')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-29T09:17:52.861482Z","iopub.status.busy":"2022-08-29T09:17:52.861203Z","iopub.status.idle":"2022-08-29T09:17:52.873501Z","shell.execute_reply":"2022-08-29T09:17:52.872351Z","shell.execute_reply.started":"2022-08-29T09:17:52.861454Z"},"papermill":{"duration":0.023057,"end_time":"2022-08-29T06:36:21.974596","exception":false,"start_time":"2022-08-29T06:36:21.951539","status":"completed"},"pycharm":{"name":"#%%\n"},"tags":[],"trusted":true},"outputs":[],"source":["class EffnetDataSet(torch.utils.data.Dataset):    \n","    def __init__(self, df, path, transforms=None):\n","        super().__init__()\n","        self.df = df\n","        self.path = path\n","        self.transforms = transforms\n","        \n","    def __getitem__(self, i):\n","        path = os.path.join(self.path, self.df.iloc[i].StudyInstanceUID, f'{self.df.iloc[i].Slice}.dcm')        \n","        \n","        try:\n","            img = load_dicom(path)[0]         \n","            img = np.transpose(img, (2, 0, 1))  # Pytorch uses (batch, channel, height, width) order. Converting (height, width, channel) -> (channel, height, width)\n","            if self.transforms is not None:\n","                img = self.transforms(torch.as_tensor(img))\n","        except Exception as ex:\n","            print(ex)\n","            return None\n","        \n","        if 'C1_fracture' in self.df:\n","            frac_targets = torch.as_tensor(self.df.iloc[i][['C1_fracture', 'C2_fracture', 'C3_fracture', 'C4_fracture', 'C5_fracture', 'C6_fracture', 'C7_fracture']].astype('float32').values)\n","            vert_targets = torch.as_tensor(self.df.iloc[i][['C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7']].astype('float32').values)\n","            frac_targets = frac_targets * vert_targets   # we only enable targets that are visible on the current slice\n","            return img, frac_targets, vert_targets\n","        return img        \n","    \n","    def __len__(self):\n","        return len(self.df)\n","    "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-29T09:17:52.875769Z","iopub.status.busy":"2022-08-29T09:17:52.875369Z","iopub.status.idle":"2022-08-29T09:17:52.909623Z","shell.execute_reply":"2022-08-29T09:17:52.908775Z","shell.execute_reply.started":"2022-08-29T09:17:52.875731Z"},"papermill":{"duration":0.04504,"end_time":"2022-08-29T06:36:22.02892","exception":false,"start_time":"2022-08-29T06:36:21.98388","status":"completed"},"pycharm":{"name":"#%%\n"},"tags":[],"trusted":true},"outputs":[],"source":["# Only X values returned by the test dataset\n","ds_test = EffnetDataSet(df_test_slices, TEST_IMAGES_PATH, WEIGHTS.transforms())\n","X = ds_test[42]\n","X.shape"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.008956,"end_time":"2022-08-29T06:36:22.047427","exception":false,"start_time":"2022-08-29T06:36:22.038471","status":"completed"},"pycharm":{"name":"#%% md\n"},"tags":[]},"source":["<div class=\"alert alert-block alert-success\" style=\"font-size:25px\">\n","    ü¶¥ 4. Model ü¶¥\n","</div>\n","\n","\n","In Pytorch we use create_feature_extractor to access feature layers of pre-existing models. Final flat layer of `efficientnet_v2_s` model is called `flatten`. We'll build our classification layer on top of it. "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-29T09:17:52.912762Z","iopub.status.busy":"2022-08-29T09:17:52.912016Z","iopub.status.idle":"2022-08-29T09:17:54.755221Z","shell.execute_reply":"2022-08-29T09:17:54.754119Z","shell.execute_reply.started":"2022-08-29T09:17:52.912718Z"},"papermill":{"duration":2.094724,"end_time":"2022-08-29T06:36:24.151144","exception":false,"start_time":"2022-08-29T06:36:22.05642","status":"completed"},"pycharm":{"name":"#%%\n"},"tags":[],"trusted":true},"outputs":[],"source":["class EffnetModel(torch.nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        effnet = tv.models.efficientnet_v2_s()\n","        self.model = create_feature_extractor(effnet, ['flatten'])\n","        self.nn_fracture = torch.nn.Sequential(\n","            torch.nn.Linear(1280, 7),\n","        )\n","        self.nn_vertebrae = torch.nn.Sequential(\n","            torch.nn.Linear(1280, 7),\n","        )\n","\n","    def forward(self, x):\n","        # returns logits\n","        x = self.model(x)['flatten']\n","        return self.nn_fracture(x), self.nn_vertebrae(x)\n","\n","    def predict(self, x):\n","        frac, vert = self.forward(x)\n","        return torch.sigmoid(frac), torch.sigmoid(vert)\n","\n","model = EffnetModel()\n","model.predict(torch.randn(1, 3, 512, 512))\n","del model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-29T09:17:54.757319Z","iopub.status.busy":"2022-08-29T09:17:54.756701Z","iopub.status.idle":"2022-08-29T09:17:54.76391Z","shell.execute_reply":"2022-08-29T09:17:54.762319Z","shell.execute_reply.started":"2022-08-29T09:17:54.757279Z"},"papermill":{"duration":0.019322,"end_time":"2022-08-29T06:36:24.180428","exception":false,"start_time":"2022-08-29T06:36:24.161106","status":"completed"},"pycharm":{"name":"#%%\n"},"tags":[],"trusted":true},"outputs":[],"source":["def load_model(model, name, path='.'):\n","    data = torch.load(os.path.join(path, f'{name}.tph'), map_location=DEVICE)\n","    model.load_state_dict(data)\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-29T09:17:54.766389Z","iopub.status.busy":"2022-08-29T09:17:54.765936Z","iopub.status.idle":"2022-08-29T09:18:01.013975Z","shell.execute_reply":"2022-08-29T09:18:01.012802Z","shell.execute_reply.started":"2022-08-29T09:17:54.766352Z"},"papermill":{"duration":4.116502,"end_time":"2022-08-29T06:36:28.306547","exception":false,"start_time":"2022-08-29T06:36:24.190045","status":"completed"},"pycharm":{"name":"#%%\n"},"tags":[],"trusted":true},"outputs":[],"source":["effnet_models = [load_model(EffnetModel(), name, EFFNET_CHECKPOINTS_PATH).to(DEVICE) for name in MODEL_NAMES]"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.008912,"end_time":"2022-08-29T06:36:28.325049","exception":false,"start_time":"2022-08-29T06:36:28.316137","status":"completed"},"pycharm":{"name":"#%% md\n"},"tags":[]},"source":["<div class=\"alert alert-block alert-success\" style=\"font-size:25px\">\n","    ü¶¥ 7. Submission ü¶¥\n","</div>\n","\n","1. We run all baseline `effnet_model` on every image from the test set and average outputs \n","2. We pass average outputs of the base `effnet_model` to the `lstm_model` to produce the final result for each patient."]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false,"execution":{"iopub.execute_input":"2022-08-29T09:18:01.01607Z","iopub.status.busy":"2022-08-29T09:18:01.015681Z","iopub.status.idle":"2022-08-29T09:18:04.568384Z","shell.execute_reply":"2022-08-29T09:18:04.567155Z","shell.execute_reply.started":"2022-08-29T09:18:01.016026Z"},"jupyter":{"outputs_hidden":false},"papermill":{"duration":3.84226,"end_time":"2022-08-29T06:36:32.176344","exception":false,"start_time":"2022-08-29T06:36:28.334084","status":"completed"},"pycharm":{"name":"#%%\n"},"tags":[],"trusted":true},"outputs":[],"source":["from typing import List\n","\n","\n","def predict_effnet(models: List[EffnetModel], ds, max_batches=1e9):\n","    dl_test = torch.utils.data.DataLoader(ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=os.cpu_count())\n","    for m in models:\n","        m.eval()\n","\n","    with torch.no_grad():\n","        predictions = []\n","        for idx, X in enumerate(tqdm(dl_test, miniters=10)):\n","            pred = torch.zeros(len(X), 14).to(DEVICE)\n","            for m in models:\n","                y1, y2 = m.predict(X.to(DEVICE))\n","                pred += torch.concat([y1, y2], dim=1) / len(models)\n","            predictions.append(pred)\n","            if idx >= max_batches:\n","                break\n","        return torch.concat(predictions).cpu().numpy()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-29T09:18:04.570876Z","iopub.status.busy":"2022-08-29T09:18:04.570449Z","iopub.status.idle":"2022-08-29T09:18:41.714893Z","shell.execute_reply":"2022-08-29T09:18:41.713778Z","shell.execute_reply.started":"2022-08-29T09:18:04.570834Z"},"papermill":{"duration":23.579326,"end_time":"2022-08-29T06:36:55.765273","exception":false,"start_time":"2022-08-29T06:36:32.185947","status":"completed"},"pycharm":{"name":"#%%\n"},"tags":[],"trusted":true},"outputs":[],"source":["effnet_pred = predict_effnet(effnet_models, ds_test)\n","\n","df_effnet_pred = pd.DataFrame(\n","    data=effnet_pred, columns=[f'C{i}_effnet_frac' for i in range(1, 8)] + [f'C{i}_effnet_vert' for i in range(1, 8)]\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-29T09:18:41.720208Z","iopub.status.busy":"2022-08-29T09:18:41.719819Z","iopub.status.idle":"2022-08-29T09:18:41.755037Z","shell.execute_reply":"2022-08-29T09:18:41.754085Z","shell.execute_reply.started":"2022-08-29T09:18:41.720173Z"},"papermill":{"duration":0.063127,"end_time":"2022-08-29T06:36:55.844489","exception":false,"start_time":"2022-08-29T06:36:55.781362","status":"completed"},"pycharm":{"name":"#%%\n"},"tags":[],"trusted":true},"outputs":[],"source":["df_test_pred = pd.concat([df_test_slices, df_effnet_pred], axis=1).sort_values(['StudyInstanceUID', 'Slice'])\n","df_test_pred"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false,"execution":{"iopub.execute_input":"2022-08-29T09:18:41.758682Z","iopub.status.busy":"2022-08-29T09:18:41.758334Z","iopub.status.idle":"2022-08-29T09:18:42.278234Z","shell.execute_reply":"2022-08-29T09:18:42.277063Z","shell.execute_reply.started":"2022-08-29T09:18:41.75864Z"},"jupyter":{"outputs_hidden":false},"papermill":{"duration":0.629707,"end_time":"2022-08-29T06:36:56.489965","exception":false,"start_time":"2022-08-29T06:36:55.860258","status":"completed"},"pycharm":{"name":"#%%\n"},"tags":[],"trusted":true},"outputs":[],"source":["def plot_sample_patient(df_pred):\n","    patient = np.random.choice(df_pred.StudyInstanceUID)\n","    df = df_pred.query('StudyInstanceUID == @patient').reset_index()\n","\n","    df[[f'C{i}_effnet_frac' for i in range(1, 8)]].plot(\n","        title=f'Patient {patient}, fracture prediction',\n","        ax=(plt.subplot(1, 2, 1)))\n","\n","    df[[f'C{i}_effnet_vert' for i in range(1, 8)]].plot(\n","        title=f'Patient {patient}, vertebrae prediction',\n","        ax=plt.subplot(1, 2, 2)\n","    )\n","\n","plot_sample_patient(df_test_pred)"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false,"execution":{"iopub.execute_input":"2022-08-29T09:18:42.280153Z","iopub.status.busy":"2022-08-29T09:18:42.279783Z","iopub.status.idle":"2022-08-29T09:18:42.307289Z","shell.execute_reply":"2022-08-29T09:18:42.306136Z","shell.execute_reply.started":"2022-08-29T09:18:42.280116Z"},"jupyter":{"outputs_hidden":false},"papermill":{"duration":0.038032,"end_time":"2022-08-29T06:36:56.54117","exception":false,"start_time":"2022-08-29T06:36:56.503138","status":"completed"},"pycharm":{"name":"#%%\n"},"tags":[],"trusted":true},"outputs":[],"source":["\n","def patient_prediction(df):\n","    c1c7 = np.average(df[FRAC_COLS].values, axis=0, weights=df[VERT_COLS].values)\n","    pred_patient_overall = 1 - np.prod(1 - c1c7)\n","    return pd.Series(data=np.concatenate([[pred_patient_overall], c1c7]), index=['patient_overall'] + [f'C{i}' for i in range(1, 8)])\n","\n","df_patient_pred = df_test_pred.groupby('StudyInstanceUID').apply(lambda df: patient_prediction(df))\n","df_patient_pred"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false,"execution":{"iopub.execute_input":"2022-08-29T09:18:42.309593Z","iopub.status.busy":"2022-08-29T09:18:42.309222Z","iopub.status.idle":"2022-08-29T09:18:42.329803Z","shell.execute_reply":"2022-08-29T09:18:42.328454Z","shell.execute_reply.started":"2022-08-29T09:18:42.309558Z"},"jupyter":{"outputs_hidden":false},"papermill":{"duration":0.036645,"end_time":"2022-08-29T06:36:56.590835","exception":false,"start_time":"2022-08-29T06:36:56.55419","status":"completed"},"pycharm":{"name":"#%%\n"},"tags":[],"trusted":true},"outputs":[],"source":["df_sub = df_test.copy()\n","df_sub = df_sub.set_index('StudyInstanceUID').join(df_patient_pred)\n","df_sub['fractured'] = df_sub.apply(lambda r: r[r.prediction_type], axis=1)\n","df_sub"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-29T09:18:42.332459Z","iopub.status.busy":"2022-08-29T09:18:42.331726Z","iopub.status.idle":"2022-08-29T09:18:42.342683Z","shell.execute_reply":"2022-08-29T09:18:42.341688Z","shell.execute_reply.started":"2022-08-29T09:18:42.332404Z"},"papermill":{"duration":0.024447,"end_time":"2022-08-29T06:36:56.629233","exception":false,"start_time":"2022-08-29T06:36:56.604786","status":"completed"},"pycharm":{"name":"#%%\n"},"tags":[],"trusted":true},"outputs":[],"source":["df_sub[['row_id', 'fractured']].to_csv('submission.csv', index=False)"]},{"cell_type":"markdown","metadata":{"execution":{"iopub.execute_input":"2022-08-20T13:17:18.762083Z","iopub.status.busy":"2022-08-20T13:17:18.761536Z","iopub.status.idle":"2022-08-20T13:17:18.76993Z","shell.execute_reply":"2022-08-20T13:17:18.768312Z","shell.execute_reply.started":"2022-08-20T13:17:18.762038Z"},"papermill":{"duration":0.012405,"end_time":"2022-08-29T06:36:56.655243","exception":false,"start_time":"2022-08-29T06:36:56.642838","status":"completed"},"pycharm":{"name":"#%% md\n"},"tags":[]},"source":["<div class=\"alert alert-block alert-danger\" style=\"text-align:center; font-size:20px;\">\n","    ‚ù§Ô∏è Dont forget to ‚ñ≤upvote‚ñ≤ if you find this notebook usefull!  ‚ù§Ô∏è\n","</div>"]}],"metadata":{"kernelspec":{"display_name":"Python 3.9.13 ('kaggle')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"},"vscode":{"interpreter":{"hash":"63a877e1d9e1c713f8b58971c9506251a4e517f3e6d55cfdb129bae98416cf1e"}}},"nbformat":4,"nbformat_minor":4}
