{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "312a9951",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-25T09:09:09.341863Z",
     "iopub.status.busy": "2023-04-25T09:09:09.341454Z",
     "iopub.status.idle": "2023-04-25T09:09:36.498355Z",
     "shell.execute_reply": "2023-04-25T09:09:36.496852Z"
    },
    "papermill": {
     "duration": 27.167857,
     "end_time": "2023-04-25T09:09:36.501188",
     "exception": false,
     "start_time": "2023-04-25T09:09:09.333331",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /kaggle/input/monai-110/monai-1.1.0-202212191849-py3-none-any.whl\r\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from monai==1.1.0) (1.21.6)\r\n",
      "Requirement already satisfied: torch>=1.8 in /opt/conda/lib/python3.7/site-packages (from monai==1.1.0) (1.13.0+cpu)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch>=1.8->monai==1.1.0) (4.4.0)\r\n",
      "Installing collected packages: monai\r\n",
      "Successfully installed monai-1.1.0\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m1.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install /kaggle/input/monai-110/monai-1.1.0-202212191849-py3-none-any.whl\n",
    "try:\n",
    "    import monai\n",
    "    print(monai.__version__)\n",
    "except:\n",
    "    print(\"Install Monai Error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45d06825",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-25T09:09:36.513197Z",
     "iopub.status.busy": "2023-04-25T09:09:36.512386Z",
     "iopub.status.idle": "2023-04-25T09:09:36.527244Z",
     "shell.execute_reply": "2023-04-25T09:09:36.525856Z"
    },
    "papermill": {
     "duration": 0.024359,
     "end_time": "2023-04-25T09:09:36.530509",
     "exception": false,
     "start_time": "2023-04-25T09:09:36.506150",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "import torch.multiprocessing as mp\n",
    "import torch.nn.parallel\n",
    "import torch.utils.data.distributed\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.losses import DiceCELoss, FocalLoss\n",
    "from monai.metrics import DiceMetric, MeanIoU\n",
    "from monai.transforms import Activations, AsDiscrete, Compose\n",
    "from monai.utils.enums import MetricReduction\n",
    "from monai.visualize import matshow3d\n",
    "from monai.transforms.transform import Transform\n",
    "from monai.transforms.transform import MapTransform\n",
    "from monai.config import KeysCollection\n",
    "from typing import Dict, Hashable, Mapping\n",
    "from monai.config.type_definitions import NdarrayOrTensor\n",
    "# from utils.myModel import MyModel, MyModel2d, MyModel3dunet, MyFlexibleUNet2d, MyFlexibleUNet2dLSTM, MyBasicUNetPlusPlus\n",
    "\n",
    "from pathlib import Path\n",
    "from easydict import EasyDict as edict\n",
    "TEST_DIR = Path('/root/autodl-tmp/vesuvius-challenge-ink-detection/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f503cc8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-25T09:09:36.542252Z",
     "iopub.status.busy": "2023-04-25T09:09:36.541161Z",
     "iopub.status.idle": "2023-04-25T09:09:36.555060Z",
     "shell.execute_reply": "2023-04-25T09:09:36.553925Z"
    },
    "papermill": {
     "duration": 0.022595,
     "end_time": "2023-04-25T09:09:36.557758",
     "exception": false,
     "start_time": "2023-04-25T09:09:36.535163",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# args = edict(RandFlipd_prob=0.2, RandRotate90d_prob=0.2, RandScaleIntensityd_prob=0.1, RandShiftIntensityd_prob=0.1, a_max=65535.0, a_min=0.0, amp=True, b_max=255.0, b_min=0.0, batch_size=1, cache_rate=1.0, checkpoint=None, data_dir='/root/autodl-tmp/vesuvius-challenge-ink-detection', debug=False, dist_backend='nccl', dist_url='tcp://127.0.0.1:23456', distributed=False, dropout_path_rate=0.0, dropout_rate=0.0, eff='b3', feature_size=48, gpu=0, in_channels=65, infer_overlap=0.5, json_list='/root/autodl-tmp/data_split/data_split.json', logdir='./runs/512_funetlstm_b3_16_sgd_continue', loss_mode='custom', loss_weight=(2.0, 1.0), lrschedule='cosine_anneal', max_epochs=2000, mid=28, model_mode='2dfunetlstm', momentum=0.99, noamp=False, norm_name='instance', normal=False, num_channel=16, num_samples=4, optim_lr=0.0001, optim_name='sgd', out_channels=1, pretrained_dir='./pretrained_models/', pretrained_model_name='512_funetlstm_b3_16_sgd_1000.pt', rank=0, reg_weight=1e-05, resume_ckpt=True, roi_x=512, roi_y=512, roi_z=16, save_checkpoint=True, smooth_dr=1e-06, smooth_nr=0.0, space_x=1.5, space_y=1.5, space_z=1.0, spatial_dims=3, sw_batch_size=4, test_mode=False, threshold=0.4, use_checkpoint=False, use_normal_dataset=False, use_ssl_pretrained=False, val_every=10, warmup_epochs=50, workers=0, world_size=1)\n",
    "args = edict(RandFlipd_prob=0.2, RandRotate90d_prob=0.2, RandScaleIntensityd_prob=0.1, RandShiftIntensityd_prob=0.1, a_max=65535.0, a_min=0.0, amp=True, b_max=255.0, b_min=0.0, \n",
    "             batch_size=1, cache_rate=1.0, checkpoint=None, data_dir='/root/autodl-tmp/vesuvius-challenge-ink-detection', debug=False, dist_backend='nccl', dist_url='tcp://127.0.0.1:23456', \n",
    "             distributed=False, dropout_path_rate=0.0, dropout_rate=0.0, eff='b3', feature_size=48, gpu=0, in_channels=65, infer_overlap=0.5, json_list='/root/autodl-tmp/data_split/data_split.json', \n",
    "             logdir='./runs/512_funetlstm_b3_16_sgd_continue_1400', loss_mode='custom', loss_weight=(2.0, 1.0), lrschedule='cosine_anneal', max_epochs=1000, mid=26, model_mode='2dfunetlstm', \n",
    "             momentum=0.99, noamp=False, norm_name='instance', normal=False, num_channel=16, num_samples=4, optim_lr=0.0005, optim_name='adamw', out_channels=1, pretrained_dir='./pretrained_models/', \n",
    "             pretrained_model_name='512_funetlstm_b3_16_sgd_1400.pt', rank=0, reg_weight=1e-05, resume_ckpt=True, roi_x=512, roi_y=512, roi_z=16, save_checkpoint=True, smooth_dr=1e-06, smooth_nr=0.0, \n",
    "             space_x=1.5, space_y=1.5, space_z=1.0, spatial_dims=3, sw_batch_size=4, test_mode=False, threshold=0.4, use_checkpoint=False, use_normal_dataset=False, use_ssl_pretrained=False, \n",
    "             val_every=10, warmup_epochs=50, workers=0, world_size=1)\n",
    "args.data_dir = \"/kaggle/input/vesuvius-challenge-ink-detection\"\n",
    "args.pretrained_dir = \"/kaggle/input/512-funetlstm-b3-16-adamw-1800\"\n",
    "args.pretrained_model_name = \"512_funetlstm_b3_16_adamw_1800.pt\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e5c2a0",
   "metadata": {
    "papermill": {
     "duration": 0.004374,
     "end_time": "2023-04-25T09:09:36.566876",
     "exception": false,
     "start_time": "2023-04-25T09:09:36.562502",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model\n",
    "- MyModel\n",
    "- MyModel2d\n",
    "- MyModel3dunet\n",
    "- MyFlexibleUNet2d\n",
    "- MyFlexibleUNet2dLSTM \n",
    "- MyBasicUNetPlusPlus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da6db24b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-25T09:09:36.578920Z",
     "iopub.status.busy": "2023-04-25T09:09:36.578055Z",
     "iopub.status.idle": "2023-04-25T09:09:36.606994Z",
     "shell.execute_reply": "2023-04-25T09:09:36.605803Z"
    },
    "papermill": {
     "duration": 0.038035,
     "end_time": "2023-04-25T09:09:36.609691",
     "exception": false,
     "start_time": "2023-04-25T09:09:36.571656",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from monai.networks.nets import SwinUNETR, UNet, FlexibleUNet, BasicUNetPlusPlus\n",
    "from monai.networks.blocks.convolutions import Convolution\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = SwinUNETR(\n",
    "            img_size=(96,96,96),\n",
    "            in_channels=1,\n",
    "            out_channels=14,\n",
    "            feature_size=48,\n",
    "            drop_rate=0.0,\n",
    "            attn_drop_rate=0.0,\n",
    "            dropout_path_rate=0.0,\n",
    "            use_checkpoint=True,\n",
    "        )\n",
    "        # self.conv1 = Convolution(spatial_dims=3, in_channels=14, out_channels=1, kernel_size=1)\n",
    "        self.conv2 = Convolution(spatial_dims=3, in_channels=1, out_channels=1, kernel_size=(1, 1, 64), strides=1, padding=0, act=\"sigmoid\")\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        if x[0].size() != (1, 64, 64, 64):\n",
    "            print(x.size())\n",
    "            raise ValueError(\"Input size is not correct\")\n",
    "        x_out = self.swinUNETR(x)\n",
    "        # x_out = self.conv1(x_out)\n",
    "        x_out = self.conv2(x_out)\n",
    "        return x_out\n",
    "    \n",
    "    def load_swin_ckpt(self, model_dict, strict: bool = True):\n",
    "        self.swinUNETR.load_state_dict(model_dict, strict)\n",
    "        pass\n",
    "    \n",
    "class MyModel2d(nn.Module):\n",
    "    def __init__(self,img_size=(192, 192)):\n",
    "        super().__init__()\n",
    "        self.swinUNETR = SwinUNETR(\n",
    "                                img_size=img_size,\n",
    "                                in_channels=65,\n",
    "                                out_channels=1,\n",
    "                                feature_size=12,\n",
    "                                use_checkpoint=True, \n",
    "                                spatial_dims=2\n",
    "                                )\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x_out = self.swinUNETR(x)\n",
    "        return x_out\n",
    "    \n",
    "    def load_swin_ckpt(self, model_dict, strict: bool = True):\n",
    "        self.swinUNETR.load_state_dict(model_dict, strict)\n",
    "        pass\n",
    "    \n",
    "class MyModel3dunet(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.unet = UNet(\n",
    "            spatial_dims=3,\n",
    "            in_channels=1,\n",
    "            out_channels=1,\n",
    "            channels=(16, 32, 64, 128, 256),\n",
    "            strides=(2, 2, 2, 2),\n",
    "            num_res_units=2,\n",
    "        )\n",
    "        self.conv1 = Convolution(spatial_dims=3, in_channels=1, out_channels=1, kernel_size=(1, 1, 64), strides=1, padding=0, act=\"sigmoid\")\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x_out = self.unet(x)\n",
    "        x_out = self.conv1(x_out)\n",
    "        return x_out\n",
    "    \n",
    "\n",
    "class MyFlexibleUNet2d(nn.Module):\n",
    "    def __init__(self, args) -> None:\n",
    "        super().__init__()\n",
    "        self.flexibleUNet = FlexibleUNet(\n",
    "                in_channels=args.num_channel,\n",
    "                out_channels=1,\n",
    "                backbone=f\"efficientnet-{args.eff}\",\n",
    "                pretrained=True,\n",
    "                spatial_dims=2,\n",
    "                dropout=0.0,\n",
    "            )\n",
    "        self.sig = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x_out = self.flexibleUNet(x)\n",
    "        x_out = self.sig(x_out)\n",
    "        return x_out\n",
    "        \n",
    "        \n",
    "\n",
    "class ConvLSTM(nn.Module):\n",
    "    def __init__(self, in_channels=320, out_channels=320, kernel_size=1, padding=0, batch_first=True):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, padding=padding)\n",
    "        self.lstm = nn.LSTM(256, 256, batch_first=batch_first)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        last_feature = x[-1]\n",
    "\n",
    "        # print(\"Before modification:\")\n",
    "        # print(x[-1][0, 0, 0, :2])  # print a small part of the tensor\n",
    "        # print(last_feature.shape)\n",
    "        batch_size, channels, height, width = last_feature.shape\n",
    "\n",
    "        # Apply 2D convolution\n",
    "        last_feature = self.conv(last_feature)\n",
    "\n",
    "        # Reshape output for LSTM\n",
    "        last_feature = last_feature.view(batch_size, -1, height * width)\n",
    "\n",
    "        # Pass through LSTM\n",
    "        lstm_out, _ = self.lstm(last_feature)\n",
    "\n",
    "        # Reshape output back to original shape\n",
    "        last_feature = lstm_out.view(batch_size, channels, height, width)\n",
    "\n",
    "        x[-1] = last_feature\n",
    "\n",
    "        # print(\"After modification:\")\n",
    "        # print(x[-1][0, 0, 0, :2])  # print a small part of the tensor\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class MyFlexibleUNet2dLSTM(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super().__init__()\n",
    "        self.flexibleUNet = FlexibleUNet(\n",
    "            in_channels=args.num_channel,\n",
    "            out_channels=1,\n",
    "            backbone=\"efficientnet-b0\",\n",
    "            pretrained=True,\n",
    "            spatial_dims=2,\n",
    "            dropout=0.0,\n",
    "        )\n",
    "        # Add ConvLSTM layer after the last convolution layer in the encoder\n",
    "        assert args.roi_x == args.roi_y, \"ROI x and y must be the same\"\n",
    "        self.conv_lstm = ConvLSTM()\n",
    "        self.sig = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_out = self.flexibleUNet.encoder(x)\n",
    "        x_out = self.conv_lstm(x_out)\n",
    "        x_out = self.flexibleUNet.decoder(x_out)\n",
    "        x_out = self.flexibleUNet.segmentation_head(x_out)\n",
    "        x_out = self.sig(x_out)\n",
    "        return x_out\n",
    "    \n",
    "class MyBasicUNetPlusPlus(nn.Module):\n",
    "    def __init__(self, args) -> None:\n",
    "        super().__init__()\n",
    "        self.basicUNetPlusPlus = BasicUNetPlusPlus(in_channels=1, out_channels=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x_out = self.basicUNetPlusPlus(x)\n",
    "        return x_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4574ee07",
   "metadata": {
    "papermill": {
     "duration": 0.00437,
     "end_time": "2023-04-25T09:09:36.618819",
     "exception": false,
     "start_time": "2023-04-25T09:09:36.614449",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# utils\n",
    "\n",
    "- def resample_3d\n",
    "- def resample_2d\n",
    "- class Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d32f61f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-25T09:09:36.630571Z",
     "iopub.status.busy": "2023-04-25T09:09:36.629789Z",
     "iopub.status.idle": "2023-04-25T09:09:36.649307Z",
     "shell.execute_reply": "2023-04-25T09:09:36.647825Z"
    },
    "papermill": {
     "duration": 0.028737,
     "end_time": "2023-04-25T09:09:36.652201",
     "exception": false,
     "start_time": "2023-04-25T09:09:36.623464",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def resample_3d(img, target_size):\n",
    "    imx, imy, imz = img.shape\n",
    "    tx, ty, tz = target_size\n",
    "    zoom_ratio = (float(tx) / float(imx), float(ty) / float(imy), float(tz) / float(imz))\n",
    "    img_resampled = ndimage.zoom(img, zoom_ratio, order=0, prefilter=False)\n",
    "    return img_resampled\n",
    "\n",
    "def resample_2d(img, target_size):\n",
    "    imx, imy = img.shape\n",
    "    tx, ty = target_size\n",
    "    zoom_ratio = (float(tx) / float(imx), float(ty) / float(imy))\n",
    "    img_resampled = ndimage.zoom(img, zoom_ratio, order=0, prefilter=False)\n",
    "    return img_resampled\n",
    "\n",
    "class Sampler(torch.utils.data.Sampler):\n",
    "    def __init__(self, dataset, num_replicas=None, rank=None, shuffle=True, make_even=True):\n",
    "        if num_replicas is None:\n",
    "            if not torch.distributed.is_available():\n",
    "                raise RuntimeError(\n",
    "                    \"Requires distributed package to be available\")\n",
    "            num_replicas = torch.distributed.get_world_size()\n",
    "        if rank is None:\n",
    "            if not torch.distributed.is_available():\n",
    "                raise RuntimeError(\n",
    "                    \"Requires distributed package to be available\")\n",
    "            rank = torch.distributed.get_rank()\n",
    "        self.shuffle = shuffle\n",
    "        self.make_even = make_even\n",
    "        self.dataset = dataset\n",
    "        self.num_replicas = num_replicas\n",
    "        self.rank = rank\n",
    "        self.epoch = 0\n",
    "        self.num_samples = int(\n",
    "            math.ceil(len(self.dataset) * 1.0 / self.num_replicas))\n",
    "        self.total_size = self.num_samples * self.num_replicas\n",
    "        indices = list(range(len(self.dataset)))\n",
    "        self.valid_length = len(\n",
    "            indices[self.rank: self.total_size: self.num_replicas])\n",
    "\n",
    "    def __iter__(self):\n",
    "        if self.shuffle:\n",
    "            g = torch.Generator()\n",
    "            g.manual_seed(self.epoch)\n",
    "            indices = torch.randperm(len(self.dataset), generator=g).tolist()\n",
    "        else:\n",
    "            indices = list(range(len(self.dataset)))\n",
    "        if self.make_even:\n",
    "            if len(indices) < self.total_size:\n",
    "                if self.total_size - len(indices) < len(indices):\n",
    "                    indices += indices[: (self.total_size - len(indices))]\n",
    "                else:\n",
    "                    extra_ids = np.random.randint(low=0, high=len(\n",
    "                        indices), size=self.total_size - len(indices))\n",
    "                    indices += [indices[ids] for ids in extra_ids]\n",
    "            assert len(indices) == self.total_size\n",
    "        indices = indices[self.rank: self.total_size: self.num_replicas]\n",
    "        self.num_samples = len(indices)\n",
    "        return iter(indices)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "    def set_epoch(self, epoch):\n",
    "        self.epoch = epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab8ed3b",
   "metadata": {
    "papermill": {
     "duration": 0.004387,
     "end_time": "2023-04-25T09:09:36.661697",
     "exception": false,
     "start_time": "2023-04-25T09:09:36.657310",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Custom Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45d3ee1a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-25T09:09:36.674620Z",
     "iopub.status.busy": "2023-04-25T09:09:36.674165Z",
     "iopub.status.idle": "2023-04-25T09:09:36.685305Z",
     "shell.execute_reply": "2023-04-25T09:09:36.683841Z"
    },
    "papermill": {
     "duration": 0.021554,
     "end_time": "2023-04-25T09:09:36.688480",
     "exception": false,
     "start_time": "2023-04-25T09:09:36.666926",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Copy(Transform):\n",
    "    def __init__(self, num_channel, add_channel=False):\n",
    "        self.num_channel = num_channel\n",
    "        self.add_channel = add_channel\n",
    "\n",
    "    def __call__(self, data):\n",
    "        if self.add_channel:\n",
    "            data = data.repeat(1, self.num_channel, 1, 1)  # output = (batch_size=1, num_channel, H, W)\n",
    "        else:\n",
    "            data = data.repeat(self.num_channel, 1, 1)  # output = (batch_size=1, num_channel, H, W)\n",
    "        return data\n",
    "    \n",
    "class Copyd(MapTransform):\n",
    "    \"\"\"\n",
    "    Dictionary-based wrapper of :py:class:`monai.transforms.AddChannel`.\n",
    "    \"\"\"\n",
    "    def __init__(self, keys: KeysCollection, num_channel, add_channel=False) -> None:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            keys: keys of the corresponding items to be transformed.\n",
    "                See also: :py:class:`monai.transforms.compose.MapTransform`\n",
    "            allow_missing_keys: don't raise exception if key is missing.\n",
    "        \"\"\"\n",
    "        super().__init__(keys, )\n",
    "        self.adder = Copy(num_channel, add_channel)\n",
    "\n",
    "    def __call__(self, data: Mapping[Hashable, NdarrayOrTensor]) -> Dict[Hashable, NdarrayOrTensor]:\n",
    "        d = dict(data)\n",
    "        for key in self.key_iterator(d):\n",
    "            d[key] = self.adder(d[key])\n",
    "        return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d45bc3e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-25T09:09:36.701611Z",
     "iopub.status.busy": "2023-04-25T09:09:36.700183Z",
     "iopub.status.idle": "2023-04-25T09:09:36.711998Z",
     "shell.execute_reply": "2023-04-25T09:09:36.710817Z"
    },
    "papermill": {
     "duration": 0.021351,
     "end_time": "2023-04-25T09:09:36.715069",
     "exception": false,
     "start_time": "2023-04-25T09:09:36.693718",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from monai.data import load_decathlon_datalist\n",
    "from monai import data, transforms\n",
    "\n",
    "def get_loader(args):\n",
    "    data_dir = args.data_dir\n",
    "    datalist_json = os.path.join(data_dir, args.json_list)\n",
    "    test_transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.LoadImaged(\n",
    "                keys=[\"image\", \"label\"], reader=\"NumpyReader\"),\n",
    "            Copyd(keys=[\"label\"],\n",
    "                    num_channel=args.num_channel),\n",
    "            transforms.AddChanneld(keys=[\"image\", 'label']),\n",
    "            # transforms.CropForegroundd(\n",
    "            #     keys=[\"image\", \"label\"], source_key=\"image\"),\n",
    "            # transforms.Orientationd(keys=[\"image\"], axcodes=\"RAS\"),\n",
    "            # change_channeld(keys=[\"image\", \"label\", 'inklabels']),\n",
    "            # transforms.Spacingd(keys=\"image\", pixdim=(args.space_x, args.space_y, args.space_z), mode=\"bilinear\"),\n",
    "            transforms.ScaleIntensityRanged(\n",
    "                keys=[\"image\"], a_min=args.a_min, a_max=args.a_max, b_min=args.b_min, b_max=args.b_max, clip=True\n",
    "            ),\n",
    "            transforms.ToTensord(keys=[\"image\"]),\n",
    "        ]\n",
    "    )\n",
    "    val_files = load_decathlon_datalist(\n",
    "        datalist_json, True, \"testing\", base_dir=data_dir)\n",
    "    val_ds = data.Dataset(data=val_files, transform=test_transform)\n",
    "    val_sampler = Sampler(\n",
    "        val_ds, shuffle=False) if args.distributed else None\n",
    "    val_loader = data.DataLoader(\n",
    "        val_ds, batch_size=8, shuffle=False, num_workers=args.workers, sampler=val_sampler, pin_memory=True\n",
    "    )\n",
    "    loader = val_loader\n",
    "    return loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d1f1a2",
   "metadata": {
    "papermill": {
     "duration": 0.004311,
     "end_time": "2023-04-25T09:09:36.724086",
     "exception": false,
     "start_time": "2023-04-25T09:09:36.719775",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Test Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "861fb303",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-25T09:09:36.735727Z",
     "iopub.status.busy": "2023-04-25T09:09:36.734823Z",
     "iopub.status.idle": "2023-04-25T09:09:36.748196Z",
     "shell.execute_reply": "2023-04-25T09:09:36.746773Z"
    },
    "papermill": {
     "duration": 0.022243,
     "end_time": "2023-04-25T09:09:36.750867",
     "exception": false,
     "start_time": "2023-04-25T09:09:36.728624",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from utils.utils import resample_3d, resample_2d\n",
    "\n",
    "def test(model_infer, val_loader, args):\n",
    "    output_directory = Path(\"/kaggle/working/\") / args.exp_name\n",
    "    output_directory.mkdir(parents=True, exist_ok=True)\n",
    "    with torch.no_grad():\n",
    "        dice_list_case = []\n",
    "        for i, batch in enumerate(val_loader):\n",
    "            val_inputs, val_labels = (batch[\"image\"].cuda(), batch[\"label\"].cuda())\n",
    "            print(type(val_labels))\n",
    "            print(val_labels.shape)\n",
    "            _, d, h, w = val_labels.shape\n",
    "            target_shape = (h, w)\n",
    "            img_name = batch[\"image_meta_dict\"][\"filename_or_obj\"][0].split(\"/\")[-1]\n",
    "            print(\"Inference on case {}\".format(img_name))\n",
    "            val_outputs = model_infer(val_inputs)\n",
    "            print(val_outputs.shape)\n",
    "            val_outputs = torch.softmax(val_outputs, 1).cpu()\n",
    "            val_outputs = np.array(val_outputs)\n",
    "            val_outputs = np.argmax(val_outputs, axis=1).astype(np.uint8)[0]\n",
    "            val_labels = val_labels.cpu()\n",
    "            val_labels = np.array(val_labels)[0, 0, :, :]\n",
    "            if args.model_mode in [\"2dswin\", \"2dfunetlstm\"]:\n",
    "                val_outputs = resample_2d(val_outputs, target_shape)\n",
    "            elif args.model_mode == \"3dswin\":\n",
    "                val_outputs = resample_3d(val_outputs, target_shape)\n",
    "            else:\n",
    "                raise ValueError(\"model_mode should be ['3dswin', '2dswin', '3dunet', '2dunet']\")\n",
    "\n",
    "            np.save(\n",
    "                os.path.join(output_directory, img_name), val_outputs[:,:]\n",
    "            )\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8fd9ea3e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-25T09:09:36.762390Z",
     "iopub.status.busy": "2023-04-25T09:09:36.761936Z",
     "iopub.status.idle": "2023-04-25T09:09:36.769465Z",
     "shell.execute_reply": "2023-04-25T09:09:36.767824Z"
    },
    "papermill": {
     "duration": 0.017118,
     "end_time": "2023-04-25T09:09:36.772664",
     "exception": false,
     "start_time": "2023-04-25T09:09:36.755546",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# np.set_printoptions(formatter={\"float\": \"{: 0.3f}\".format}, suppress=True)\n",
    "\n",
    "# torch.cuda.set_device(0)\n",
    "# torch.backends.cudnn.benchmark = True\n",
    "# args.test_mode = True\n",
    "# loader = get_loader(args)\n",
    "\n",
    "# inf_size = [args.roi_x, args.roi_y, args.roi_z]\n",
    "\n",
    "# pretrained_dir = args.pretrained_dir\n",
    "# if args.model_mode == \"3dswin\":\n",
    "#     model = MyModel(img_size=(args.roi_x,args.roi_y,args.roi_y))\n",
    "# elif args.model_mode == \"2dswin\":\n",
    "#     model = MyModel2d(img_size=(args.roi_x,args.roi_y))\n",
    "# elif args.model_mode == \"3dunet\":\n",
    "#     model = MyModel3dunet()\n",
    "# elif args.model_mode == \"2dfunet\":\n",
    "#     model = MyFlexibleUNet2d(args)\n",
    "# elif args.model_mode == \"2dfunetlstm\":\n",
    "#     model = MyFlexibleUNet2dLSTM(args)\n",
    "# elif args.model_mode == \"3dunet++\":\n",
    "#     model = MyBasicUNetPlusPlus(args)\n",
    "# else:\n",
    "#     raise ValueError(\"model mode error\")\n",
    "\n",
    "\n",
    "# model_dict = torch.load(os.path.join(pretrained_dir, args.pretrained_model_name))[\"state_dict\"]\n",
    "# if args.model_mode in [\"2dswin\", \"3dunet\", \"2dfunet\", \"2dfunetlstm\", \"3dunet++\"]:\n",
    "#     model.load_state_dict(model_dict)\n",
    "# elif args.model_mode == \"3dswin\":\n",
    "#     model.load_swin_ckpt(model_dict)\n",
    "# else:\n",
    "#     raise ValueError(\"model mode error\")\n",
    "\n",
    "# if args.model_mode in [\"3dswin\", \"3dunet\", \"3dunet++\"]:\n",
    "#     model_inferer = partial(\n",
    "#         sliding_window_inference,\n",
    "#         roi_size = (args.roi_x,args.roi_y,args.roi_z),\n",
    "#         sw_batch_size = 8,\n",
    "#         predictor = model,\n",
    "#         overlap = 0.5,\n",
    "#         progress = True,\n",
    "#         padding_mode = \"reflect\", \n",
    "#         device = \"cpu\", \n",
    "#         sw_device = \"cuda\"\n",
    "#     )\n",
    "# elif args.model_mode in [\"2dswin\", \"2dfunet\", \"2dfunetlstm\"]:\n",
    "#     model_inferer = partial(\n",
    "#         sliding_window_inference,\n",
    "#         roi_size = (args.roi_x,args.roi_y),\n",
    "#         sw_batch_size = 8,\n",
    "#         predictor = model,\n",
    "#         overlap = 0.5,\n",
    "#         progress = True,\n",
    "#         padding_mode = \"reflect\", \n",
    "#         device = \"cpu\", \n",
    "#         sw_device = \"cuda\"\n",
    "#     )     \n",
    "# else:\n",
    "#     raise ValueError(\"model mode error\")\n",
    "\n",
    "# model.cuda(0)\n",
    "\n",
    "# print(args)\n",
    "# #test(model_inferer, loader, args)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 42.059599,
   "end_time": "2023-04-25T09:09:39.177030",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-04-25T09:08:57.117431",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
