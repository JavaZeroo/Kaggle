{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "348e7236",
   "metadata": {
    "papermill": {
     "duration": 0.013218,
     "end_time": "2022-09-03T12:10:01.105833",
     "exception": false,
     "start_time": "2022-09-03T12:10:01.092615",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-success\" style=\"font-size:30px\">\n",
    "ü¶¥ [train] PyTorch-EfficientNetV2 baseline CV:0.49 ü¶¥\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\" style=\"text-align:center; font-size:20px;\">\n",
    "    ‚ù§Ô∏è Dont forget to ‚ñ≤upvote‚ñ≤ if you find this notebook usefull!  ‚ù§Ô∏è\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    <ul>\n",
    "        <li>\n",
    "            üìå This is a training part. For <b>inference</b> refer to: <a href=\"https://www.kaggle.com/code/vslaykovsky/infer-pytorch-effnetv2-single-model-pl-0-49\">Pytorch EfficientNet-v2 single model PL:0.49, ensemble PL:0.47</a>\n",
    "        </li>\n",
    "        <li>\n",
    "            üìå Note that this notebook depends on <b>vertebrae detection dataset</b>. Check it out here: <a href=\"https://www.kaggle.com/code/vslaykovsky/pytorch-effnetv2-vertebrae-detection-acc-0-95\">PyTorch-EffNetV2 vertebrae detection (acc: 0.95)</a>\n",
    "        </li>\n",
    "        <li>\n",
    "            üìå To run the notebook in non-interactive mode, <b>set Add-ons->Secrets->WANDB_API_KEY</b> secret key to the value of your <a href=\"https://wandb.ai/authorize\">Wandb API key. </a>\n",
    "        </li>        \n",
    "</div>\n",
    "\n",
    "\n",
    "This is a bare-bones PyTorch implementation of EfficientNet-v2 based classifier. This is a simple baseline implementation that can be iteratively improved.\n",
    "\n",
    "\n",
    "<img src=\"https://images2.imgbox.com/cd/58/AeY81v9Y_o.png\" alt=\"image host\"/>\n",
    "\n",
    "\n",
    "Here is the high level overview of the training flow:\n",
    "1. Images are loaded from train folder and transformed to `3x384x384` tensors using the same transformations used to pretrain `EfficientNet_V2_S` on ImageNet 1000.\n",
    "2. Images are passed to a pre-trained encoder of `EfficientNet_V2_S`. We ignore the final classification layer of the `EfficientNet_V2_S`, because it's shape is irrelevant given the current task. The most valuable layer of `EfficientNet_V2_S` that we'll use as a base for our final classification layer is the flattened (1280,) layer. (1280,) is then transformed to 2 parallel (7,) `Linear` layers followed by a sigmoid nonlinearity. Note that we use logits in the loss function to improve numerical stability.\n",
    "3. Vertebrae fracture targets are loaded from `train.csv` file. Vertebrae detection targets are loaded from `train_segmented.csv` which comes from <a href=\"https://www.kaggle.com/code/vslaykovsky/pytorch-effnetv2-vertebrae-detection-acc-0-95\">PyTorch-EffNetV2 vertebrae detection (acc: 0.95)</a>. We only predict fractures that are visible on the current slice by masking fracture targets with visible vertebrae targets. Visible vertebrae targets are passed to the loss function as is without modifications.\n",
    "4. Predictions and targets are passed to BCELoss which is a muti-label loss function that optimizes 7 independent binary classification targets for C1-C7. Don't confuse this with the multiclass crossentropy loss. Additionally, we implement weighted loss for fracture targets.\n",
    "5. In the end we get a model that detects fractures and visible C1-C7 vertebrae using a single image. We need to figure out how to estimate the final result with 1 record per StudyInstanceUID, rather than 1 record per scan. We use a non-parametric model to combine predictions of base models:    \n",
    "    * For each StudyInstanceUID we first aggregate predictions for each of C1-C7 vertebrae by weighted averaging fracture predictions. Probabilities of vertebrae are used as weights. Example: if we are uncertain that C3 is in the slice (`C3_effnet_vert==0.1`), but we somehow predict high probability of C3 being fractured (`C3_effnet_frac==0.9`), we add it to the final aggregate with low weight `0.9 * 0.1 == 0.09`\n",
    "    * We use a simple probability formula to derive `patient_overall` fracture probability. `patient_overall` is a probability of any vertebrae being fractured. It is equal to `1-no-vertebrae-are-fractured`. Under assumption of independence of vertebrae fractures we can derive the following simple equation: $P_{\\text{patient_overall}}=1-\\prod_i{[1-C_i]}$\n",
    "\n",
    "\n",
    "\n",
    "### Ideas implemented in this notebook\n",
    "\n",
    "1. Decoding **JPEG-encoded scans** along with regular scans to increase the size of training set.\n",
    "\n",
    "2. **Train-eval splitting based on patient id** (StudyInstanceUID). Using GroupKFold with patient id as a group id. This makes evaluation result more accurate as there is significant correlation between close scans from the same patient.\n",
    "\n",
    "3. **Weighted loss optimization.**. Adjusting weights of classes to optimize the same loss function as the one used in scoring of the solution.\n",
    "\n",
    "\n",
    "$$\n",
    "L_{ij} = - w_j \\left(y_{ij} \\log(p_{ij}) + (1-y_{ij}) \\log(1-p_{ij})  \\right)\n",
    "$$\n",
    "\n",
    "where the **weights** [are given by](https://www.kaggle.com/competitions/rsna-2022-cervical-spine-fracture-detection/discussion/340392)\n",
    "\n",
    "$$\n",
    "w_{j} = \\begin{cases}\n",
    "1, \\qquad \\text{if vertebrae negative} \\\\\n",
    "2, \\qquad \\text{if vertebrae positive} \\\\\n",
    "7, \\qquad \\text{if patient negative} \\\\\n",
    "14, \\qquad \\text{if patient positive}\n",
    "\\end{cases}\n",
    "$$\n",
    "Note, that the base EfficientNet-v2 model only uses the first two weights.\n",
    "\n",
    "4. **Accurate loss evaluation**. Evaluation using the same exact loss function used in scoring of the final solution.\n",
    "\n",
    "5. **OneCycleLR**. OneCyleLR is often the best choice of scheduler with limited compute. Read more about it here: https://sgugger.github.io/the-1cycle-policy.html\n",
    "\n",
    "![45YUYb.md.png](https://iili.io/45YUYb.md.png)\n",
    "\n",
    "6. **Mixed-precision** training with gradient scaling is implemented to speed up training on Nvidia Ampere architectures.\n",
    "\n",
    "7. Using **Wandb** for logging.\n",
    "\n",
    "8. Removed \"1.2.826.0.1.3680043.20574\" https://www.kaggle.com/competitions/rsna-2022-cervical-spine-fracture-detection/discussion/344862\n",
    "\n",
    "9. Training data is **subsampled**. E.g. we don't use all 100% samples here to avoid overfitting. To reduce overfitting try adding augmentations/regularization to your pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f0303c",
   "metadata": {
    "papermill": {
     "duration": 0.010875,
     "end_time": "2022-09-03T12:10:01.127432",
     "exception": false,
     "start_time": "2022-09-03T12:10:01.116557",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-success\" style=\"font-size:25px\">\n",
    "ü¶¥ 1. Imports, constants, dependencies ü¶¥\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624fc9dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-03T12:10:01.153012Z",
     "iopub.status.busy": "2022-09-03T12:10:01.151781Z",
     "iopub.status.idle": "2022-09-03T12:11:12.928074Z",
     "shell.execute_reply": "2022-09-03T12:11:12.926902Z"
    },
    "papermill": {
     "duration": 71.792447,
     "end_time": "2022-09-03T12:11:12.930741",
     "exception": false,
     "start_time": "2022-09-03T12:10:01.138294",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    # import pylibjpeg\n",
    "    print(\"import pylibjpeg\")\n",
    "except:\n",
    "    # The following *.whl files were collected from these pip packages:\n",
    "    #!pip install -U \"python-gdcm\" pydicom pylibjpeg    # Required for JPEG decompression. See: https://www.kaggle.com/competitions/rsna-2022-cervical-spine-fracture-detection/discussion/341412\n",
    "    #!pip install -U torchvision                        # For EfficientNetV2\n",
    "\n",
    "    # Offline dependencies:\n",
    "    !mkdir -p /root/.cache/torch/hub/checkpoints/\n",
    "    !cp ../input/rsna-2022-whl/efficientnet_v2_s-dd5fe13b.pth  /root/.cache/torch/hub/checkpoints/\n",
    "    !pip install /kaggle/input/rsna-2022-whl/{pydicom-2.3.0-py3-none-any.whl,pylibjpeg-1.4.0-py3-none-any.whl,python_gdcm-3.0.15-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl}\n",
    "    !pip install /kaggle/input/rsna-2022-whl/{torch-1.12.1-cp37-cp37m-manylinux1_x86_64.whl,torchvision-0.13.1-cp37-cp37m-manylinux1_x86_64.whl}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad90acf7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-03T12:11:12.954370Z",
     "iopub.status.busy": "2022-09-03T12:11:12.954011Z",
     "iopub.status.idle": "2022-09-03T12:11:16.184214Z",
     "shell.execute_reply": "2022-09-03T12:11:16.182901Z"
    },
    "papermill": {
     "duration": 3.245253,
     "end_time": "2022-09-03T12:11:16.187201",
     "exception": false,
     "start_time": "2022-09-03T12:11:12.941948",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pydicom as dicom\n",
    "import torch\n",
    "import torchvision as tv\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from torchvision.models.feature_extraction import create_feature_extractor\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import wandb\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (20, 5)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', 1000)\n",
    "\n",
    "# Effnet\n",
    "WEIGHTS = tv.models.efficientnet.EfficientNet_V2_S_Weights.DEFAULT\n",
    "RSNA_2022_PATH = '../input/rsna-2022-cervical-spine-fracture-detection'\n",
    "TRAIN_IMAGES_PATH = f'{RSNA_2022_PATH}/train_images'\n",
    "TEST_IMAGES_PATH = f'{RSNA_2022_PATH}/test_images'\n",
    "EFFNET_MAX_TRAIN_BATCHES = 4000\n",
    "EFFNET_MAX_EVAL_BATCHES = 200\n",
    "ONE_CYCLE_MAX_LR = 0.0001\n",
    "ONE_CYCLE_PCT_START = 0.3\n",
    "SAVE_CHECKPOINT_EVERY_STEP = 1000\n",
    "EFFNET_CHECKPOINTS_PATH = '../input/rsna-2022-base-effnetv2'\n",
    "FRAC_LOSS_WEIGHT = 2.\n",
    "N_FOLDS = 5\n",
    "METADATA_PATH = '../input/vertebrae-detection-checkpoints'\n",
    "\n",
    "PREDICT_MAX_BATCHES = 1e9\n",
    "\n",
    "# Common\n",
    "try:\n",
    "    from kaggle_secrets import UserSecretsClient\n",
    "    IS_KAGGLE = True\n",
    "except:\n",
    "    IS_KAGGLE = False\n",
    "\n",
    "os.environ[\"WANDB_MODE\"] = \"online\"\n",
    "if os.environ[\"WANDB_MODE\"] == \"online\":\n",
    "    if IS_KAGGLE:\n",
    "        os.environ['WANDB_API_KEY'] = UserSecretsClient().get_secret(\"WANDB_API_KEY\")\n",
    "\n",
    "if not IS_KAGGLE:\n",
    "    print('Running locally')\n",
    "    RSNA_2022_PATH = r'/mnt/e/Code/Kaggle/RSNA_data'\n",
    "    TRAIN_IMAGES_PATH = r'/mnt/e/Code/Kaggle/RSNA_data/train_images'\n",
    "    TEST_IMAGES_PATH = r'/mnt/e/Code/Kaggle/RSNA_data/test_images'\n",
    "    METADATA_PATH = r'/mnt/e/Code/Kaggle/RSNA_data/Metadata'\n",
    "    EFFNET_CHECKPOINTS_PATH = r'/mnt/e/Code/Kaggle/RSNA_data/effnetv2'\n",
    "    os.environ['WANDB_API_KEY'] = '67c99389e1ae37b747c40634c51802a4bf019d49'\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "if DEVICE == 'cuda':\n",
    "    BATCH_SIZE = 32\n",
    "else:\n",
    "    BATCH_SIZE = 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26695f7b",
   "metadata": {
    "papermill": {
     "duration": 0.010649,
     "end_time": "2022-09-03T12:11:16.208837",
     "exception": false,
     "start_time": "2022-09-03T12:11:16.198188",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-success\" style=\"font-size:25px\">\n",
    "    ü¶¥ 2. Loading train/eval/test dataframes ü¶¥\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3611b80",
   "metadata": {
    "papermill": {
     "duration": 0.010377,
     "end_time": "2022-09-03T12:11:16.230373",
     "exception": false,
     "start_time": "2022-09-03T12:11:16.219996",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "### Train data\n",
    "\n",
    "1. Loading data from competition dataset folder `../input/rsna-2022-cervical-spine-fracture-detection/train.csv`\n",
    "2. Joining data with slice information from metadata dataset `../input/rsna-2022-spine-fracture-detection-metadata/meta_train_with_vertebrae.csv`\n",
    "3. Adding `Splits` column to facilitate train/eval splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0517a5ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-03T12:11:16.254409Z",
     "iopub.status.busy": "2022-09-03T12:11:16.253127Z",
     "iopub.status.idle": "2022-09-03T12:11:16.298343Z",
     "shell.execute_reply": "2022-09-03T12:11:16.297406Z"
    },
    "papermill": {
     "duration": 0.059318,
     "end_time": "2022-09-03T12:11:16.300333",
     "exception": false,
     "start_time": "2022-09-03T12:11:16.241015",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(f'{RSNA_2022_PATH}/train.csv')\n",
    "print(df_train.shape)\n",
    "df_train = df_train.drop(df_train[df_train.StudyInstanceUID=='1.2.826.0.1.3680043.20756'].index)\n",
    "df_train = df_train.drop(df_train[df_train.StudyInstanceUID=='1.2.826.0.1.3680043.20574'].index)\n",
    "df_train = df_train.drop(df_train[df_train.StudyInstanceUID=='1.2.826.0.1.3680043.29952'].index)\n",
    "print(df_train.shape)\n",
    "df_train.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6aea4b3",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-09-03T12:11:16.323949Z",
     "iopub.status.busy": "2022-09-03T12:11:16.323284Z",
     "iopub.status.idle": "2022-09-03T12:11:18.375993Z",
     "shell.execute_reply": "2022-09-03T12:11:18.373938Z"
    },
    "papermill": {
     "duration": 2.066615,
     "end_time": "2022-09-03T12:11:18.378206",
     "exception": false,
     "start_time": "2022-09-03T12:11:16.311591",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# rsna-2022-spine-fracture-detection-metadata contains inference of C1-C7 vertebrae for all training sample (95% accuracy)\n",
    "df_train_slices = pd.read_csv(f'{METADATA_PATH}/train_segmented.csv')\n",
    "c1c7 = [f'C{i}' for i in range(1, 8)]\n",
    "df_train_slices[c1c7] = (df_train_slices[c1c7] > 0.5).astype(int)\n",
    "print(df_train_slices.sample(5)[['StudyInstanceUID', 'C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d4aa4b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-03T12:11:18.403452Z",
     "iopub.status.busy": "2022-09-03T12:11:18.401808Z",
     "iopub.status.idle": "2022-09-03T12:11:18.996268Z",
     "shell.execute_reply": "2022-09-03T12:11:18.995200Z"
    },
    "papermill": {
     "duration": 0.609125,
     "end_time": "2022-09-03T12:11:18.998474",
     "exception": false,
     "start_time": "2022-09-03T12:11:18.389349",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train = df_train_slices.set_index('StudyInstanceUID').join(df_train.set_index('StudyInstanceUID'),\n",
    "                                                              rsuffix='_fracture').reset_index().copy()\n",
    "df_train = df_train.query('StudyInstanceUID != \"1.2.826.0.1.3680043.20574\"').reset_index(drop=True)\n",
    "df_train.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b69d0f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-03T12:11:19.023764Z",
     "iopub.status.busy": "2022-09-03T12:11:19.022294Z",
     "iopub.status.idle": "2022-09-03T12:11:19.497909Z",
     "shell.execute_reply": "2022-09-03T12:11:19.496314Z"
    },
    "papermill": {
     "duration": 0.491261,
     "end_time": "2022-09-03T12:11:19.501277",
     "exception": false,
     "start_time": "2022-09-03T12:11:19.010016",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "split = GroupKFold(N_FOLDS)\n",
    "for k, (_, test_idx) in enumerate(split.split(df_train, groups=df_train.StudyInstanceUID)):\n",
    "    df_train.loc[test_idx, 'split'] = k\n",
    "df_train.sample(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07071523",
   "metadata": {
    "papermill": {
     "duration": 0.023681,
     "end_time": "2022-09-03T12:11:19.551387",
     "exception": false,
     "start_time": "2022-09-03T12:11:19.527706",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "### Test data\n",
    "\n",
    "1. Loading data from competition dataset folder `../input/rsna-2022-cervical-spine-fracture-detection/test.csv`\n",
    "2. Joining data with slice information collected from test image folders `../input/rsna-2022-cervical-spine-fracture-detection/test_images/*/*`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accc5693",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-03T12:11:19.601061Z",
     "iopub.status.busy": "2022-09-03T12:11:19.600201Z",
     "iopub.status.idle": "2022-09-03T12:11:19.622428Z",
     "shell.execute_reply": "2022-09-03T12:11:19.621284Z"
    },
    "papermill": {
     "duration": 0.046181,
     "end_time": "2022-09-03T12:11:19.624395",
     "exception": false,
     "start_time": "2022-09-03T12:11:19.578214",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(f'{RSNA_2022_PATH}/test.csv')\n",
    "\n",
    "if df_test.iloc[0].row_id == '1.2.826.0.1.3680043.10197_C1':\n",
    "    # test_images and test.csv are inconsistent in the dev dataset, fixing labels for the dev run.\n",
    "    df_test = pd.DataFrame({\n",
    "        \"row_id\": ['1.2.826.0.1.3680043.22327_C1', '1.2.826.0.1.3680043.25399_C1', '1.2.826.0.1.3680043.5876_C1'],\n",
    "        \"StudyInstanceUID\": ['1.2.826.0.1.3680043.22327', '1.2.826.0.1.3680043.25399', '1.2.826.0.1.3680043.5876'],\n",
    "        \"prediction_type\": [\"C1\", \"C1\", \"patient_overall\"]}\n",
    "    )\n",
    "\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f6f0fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-03T12:11:19.672009Z",
     "iopub.status.busy": "2022-09-03T12:11:19.671675Z",
     "iopub.status.idle": "2022-09-03T12:11:19.794121Z",
     "shell.execute_reply": "2022-09-03T12:11:19.793165Z"
    },
    "papermill": {
     "duration": 0.148421,
     "end_time": "2022-09-03T12:11:19.796577",
     "exception": false,
     "start_time": "2022-09-03T12:11:19.648156",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_slices = glob.glob(f'{TEST_IMAGES_PATH}/*/*')\n",
    "# print(test_slices)\n",
    "print(test_slices[0])\n",
    "test_slices = [re.findall(fr'{TEST_IMAGES_PATH}/(.*)/(.*).dcm', fr'{s}')[0] for s in test_slices]\n",
    "print(test_slices[0])\n",
    "df_test_slices = pd.DataFrame(data=test_slices, columns=['StudyInstanceUID', 'Slice'])\n",
    "df_test_slices.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e2ef04",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-03T12:11:19.834292Z",
     "iopub.status.busy": "2022-09-03T12:11:19.833663Z",
     "iopub.status.idle": "2022-09-03T12:11:19.854556Z",
     "shell.execute_reply": "2022-09-03T12:11:19.852809Z"
    },
    "papermill": {
     "duration": 0.041915,
     "end_time": "2022-09-03T12:11:19.857050",
     "exception": false,
     "start_time": "2022-09-03T12:11:19.815135",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_test = df_test.set_index('StudyInstanceUID').join(df_test_slices.set_index('StudyInstanceUID')).reset_index()\n",
    "df_test.sample(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd76d99",
   "metadata": {
    "papermill": {
     "duration": 0.017688,
     "end_time": "2022-09-03T12:11:19.892779",
     "exception": false,
     "start_time": "2022-09-03T12:11:19.875091",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-success\" style=\"font-size:25px\">\n",
    "    ü¶¥ 3. Dataset class ü¶¥\n",
    "</div>\n",
    "\n",
    "`EffnetDataSet` class returns images of individual slices. It uses a dataframe parameter `df` as a source of slices metadata to locate and load images from `path` folder. It accepts transforms parameter which we set to `WEIGHTS.transforms()`. This is a set of transforms used to pre-train the model on ImageNet dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca9a30e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-03T12:11:19.929808Z",
     "iopub.status.busy": "2022-09-03T12:11:19.929355Z",
     "iopub.status.idle": "2022-09-03T12:11:20.486940Z",
     "shell.execute_reply": "2022-09-03T12:11:20.485986Z"
    },
    "papermill": {
     "duration": 0.578398,
     "end_time": "2022-09-03T12:11:20.489376",
     "exception": false,
     "start_time": "2022-09-03T12:11:19.910978",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_dicom(path):\n",
    "    \"\"\"\n",
    "    This supports loading both regular and compressed JPEG images. \n",
    "    See the first sell with `pip install` commands for the necessary dependencies\n",
    "    \"\"\"\n",
    "    img = dicom.dcmread(path)\n",
    "    img.PhotometricInterpretation = 'YBR_FULL'\n",
    "    data = img.pixel_array\n",
    "    data = data - np.min(data)\n",
    "    if np.max(data) != 0:\n",
    "        data = data / np.max(data)\n",
    "    data = (data * 255).astype(np.uint8)\n",
    "    return cv2.cvtColor(data, cv2.COLOR_GRAY2RGB), img\n",
    "\n",
    "\n",
    "im, meta = load_dicom(\n",
    "    f'{TRAIN_IMAGES_PATH}/1.2.826.0.1.3680043.10001/1.dcm')\n",
    "plt.figure()\n",
    "plt.imshow(im)\n",
    "plt.title('regular image')\n",
    "\n",
    "im, meta = load_dicom(\n",
    "    f'{TRAIN_IMAGES_PATH}/1.2.826.0.1.3680043.10014/1.dcm')\n",
    "plt.figure()\n",
    "plt.imshow(im)\n",
    "plt.title('jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81bc181a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-03T12:11:20.519812Z",
     "iopub.status.busy": "2022-09-03T12:11:20.519205Z",
     "iopub.status.idle": "2022-09-03T12:11:20.529860Z",
     "shell.execute_reply": "2022-09-03T12:11:20.528724Z"
    },
    "papermill": {
     "duration": 0.02789,
     "end_time": "2022-09-03T12:11:20.532034",
     "exception": false,
     "start_time": "2022-09-03T12:11:20.504144",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EffnetDataSet(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, path, transforms=None):\n",
    "        super().__init__()\n",
    "        self.df = df\n",
    "        self.path = path\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        path = os.path.join(self.path, self.df.iloc[i].StudyInstanceUID, f'{self.df.iloc[i].Slice}.dcm')\n",
    "\n",
    "        try:\n",
    "            img = load_dicom(path)[0]\n",
    "            # Pytorch uses (batch, channel, height, width) order. Converting (height, width, channel) -> (channel, height, width)\n",
    "            img = np.transpose(img, (2, 0, 1))\n",
    "            if self.transforms is not None:\n",
    "                img = self.transforms(torch.as_tensor(img))\n",
    "        except Exception as ex:\n",
    "            print(ex)\n",
    "            return None\n",
    "\n",
    "        if 'C1_fracture' in self.df:\n",
    "            frac_targets = torch.as_tensor(self.df.iloc[i][['C1_fracture', 'C2_fracture', 'C3_fracture', 'C4_fracture',\n",
    "                                                            'C5_fracture', 'C6_fracture', 'C7_fracture']].astype(\n",
    "                'float32').values)\n",
    "            vert_targets = torch.as_tensor(\n",
    "                self.df.iloc[i][['C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7']].astype('float32').values)\n",
    "            frac_targets = frac_targets * vert_targets  # we only enable targets that are visible on the current slice\n",
    "            return img, frac_targets, vert_targets\n",
    "        return img\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881c0997",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-03T12:11:20.561246Z",
     "iopub.status.busy": "2022-09-03T12:11:20.560952Z",
     "iopub.status.idle": "2022-09-03T12:11:20.590287Z",
     "shell.execute_reply": "2022-09-03T12:11:20.589284Z"
    },
    "papermill": {
     "duration": 0.047087,
     "end_time": "2022-09-03T12:11:20.592818",
     "exception": false,
     "start_time": "2022-09-03T12:11:20.545731",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds_train = EffnetDataSet(df_train, TRAIN_IMAGES_PATH, WEIGHTS.transforms())\n",
    "X, y_frac, y_vert = ds_train[42]\n",
    "print(X.shape, y_frac.shape, y_vert.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bef801a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-03T12:11:20.622656Z",
     "iopub.status.busy": "2022-09-03T12:11:20.622162Z",
     "iopub.status.idle": "2022-09-03T12:11:28.386512Z",
     "shell.execute_reply": "2022-09-03T12:11:28.385540Z"
    },
    "papermill": {
     "duration": 7.781899,
     "end_time": "2022-09-03T12:11:28.388846",
     "exception": false,
     "start_time": "2022-09-03T12:11:20.606947",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_sample_patient(df, ds):\n",
    "    patient = np.random.choice(df.query('patient_overall > 0').StudyInstanceUID)\n",
    "    df = df.query('StudyInstanceUID == @patient')\n",
    "    display(df)\n",
    "\n",
    "    frac = np.stack([ds[i][1] for i in df.index])\n",
    "    vert = np.stack([ds[i][2] for i in df.index])\n",
    "    ax = plt.subplot(1, 2, 1)\n",
    "    ax.plot(frac)\n",
    "    ax.set_title(f'Vertebrae with fractures by slice (masked by visible vertebrae). uid:{patient}')\n",
    "    ax = plt.subplot(1, 2, 2)\n",
    "    ax.set_title(f'Visible vertebrae by slice. uid:{patient}')\n",
    "    ax.plot(vert)\n",
    "\n",
    "plot_sample_patient(df_train, ds_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53369879",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-03T12:11:28.424468Z",
     "iopub.status.busy": "2022-09-03T12:11:28.422664Z",
     "iopub.status.idle": "2022-09-03T12:11:28.454128Z",
     "shell.execute_reply": "2022-09-03T12:11:28.453161Z"
    },
    "papermill": {
     "duration": 0.052223,
     "end_time": "2022-09-03T12:11:28.457515",
     "exception": false,
     "start_time": "2022-09-03T12:11:28.405292",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Only X values returned by the test dataset\n",
    "ds_test = EffnetDataSet(df_test, TEST_IMAGES_PATH, WEIGHTS.transforms())\n",
    "X = ds_test[42]\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493ffbff",
   "metadata": {
    "papermill": {
     "duration": 0.015855,
     "end_time": "2022-09-03T12:11:28.489793",
     "exception": false,
     "start_time": "2022-09-03T12:11:28.473938",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-success\" style=\"font-size:25px\">\n",
    "    ü¶¥ 4. Model ü¶¥\n",
    "</div>\n",
    "\n",
    "\n",
    "In Pytorch we use create_feature_extractor to access feature layers of pre-existing models. Final flat layer of `efficientnet_v2_s` model is called `flatten`. We'll build our classification layer on top of it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb34a45e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-03T12:11:28.523079Z",
     "iopub.status.busy": "2022-09-03T12:11:28.522129Z",
     "iopub.status.idle": "2022-09-03T12:11:30.686988Z",
     "shell.execute_reply": "2022-09-03T12:11:30.685925Z"
    },
    "papermill": {
     "duration": 2.184841,
     "end_time": "2022-09-03T12:11:30.690368",
     "exception": false,
     "start_time": "2022-09-03T12:11:28.505527",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EffnetModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        effnet = tv.models.efficientnet_v2_s(weights=WEIGHTS)\n",
    "        self.model = create_feature_extractor(effnet, ['flatten'])\n",
    "        self.nn_fracture = torch.nn.Sequential(\n",
    "            torch.nn.Linear(1280, 7),\n",
    "        )\n",
    "        self.nn_vertebrae = torch.nn.Sequential(\n",
    "            torch.nn.Linear(1280, 7),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # returns logits\n",
    "        x = self.model(x)['flatten']\n",
    "        return self.nn_fracture(x), self.nn_vertebrae(x)\n",
    "\n",
    "    def predict(self, x):\n",
    "        frac, vert = self.forward(x)\n",
    "        return torch.sigmoid(frac), torch.sigmoid(vert)\n",
    "\n",
    "model = EffnetModel()\n",
    "model.predict(torch.randn(1, 3, 512, 512))\n",
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47cecd37",
   "metadata": {
    "papermill": {
     "duration": 0.025137,
     "end_time": "2022-09-03T12:11:30.742920",
     "exception": false,
     "start_time": "2022-09-03T12:11:30.717783",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-success\" style=\"font-size:25px\">\n",
    "    ü¶¥ 5.1 Train: loss function ü¶¥\n",
    "</div>\n",
    "\n",
    "We use weighted loss here. See definition here: https://www.kaggle.com/competitions/rsna-2022-cervical-spine-fracture-detection/discussion/340392\n",
    "Weighted loss helps us to optimize the same target that is used in the final scoring.\n",
    "\n",
    "Auxiliary vertebrae detection loss is added in the training/evaluation loop to improve model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8085e6bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-03T12:11:30.793815Z",
     "iopub.status.busy": "2022-09-03T12:11:30.793183Z",
     "iopub.status.idle": "2022-09-03T12:11:30.806387Z",
     "shell.execute_reply": "2022-09-03T12:11:30.805387Z"
    },
    "papermill": {
     "duration": 0.040766,
     "end_time": "2022-09-03T12:11:30.808478",
     "exception": false,
     "start_time": "2022-09-03T12:11:30.767712",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def weighted_loss(y_pred_logit, y, reduction='mean', verbose=False):\n",
    "    \"\"\"\n",
    "    Weighted loss\n",
    "    We reuse torch.nn.functional.binary_cross_entropy_with_logits here. pos_weight and weights combined give us necessary coefficients described in https://www.kaggle.com/competitions/rsna-2022-cervical-spine-fracture-detection/discussion/340392\n",
    "\n",
    "    See also this explanation: https://www.kaggle.com/code/samuelcortinhas/rsna-fracture-detection-in-depth-eda/notebook\n",
    "    \"\"\"\n",
    "\n",
    "    neg_weights = (torch.tensor([7., 1, 1, 1, 1, 1, 1, 1]) if y_pred_logit.shape[-1] == 8 else torch.ones(y_pred_logit.shape[-1])).to(DEVICE)\n",
    "    pos_weights = (torch.tensor([14., 2, 2, 2, 2, 2, 2, 2]) if y_pred_logit.shape[-1] == 8 else torch.ones(y_pred_logit.shape[-1]) * 2.).to(DEVICE)\n",
    "\n",
    "    loss = torch.nn.functional.binary_cross_entropy_with_logits(\n",
    "        y_pred_logit,\n",
    "        y,\n",
    "        reduction='none',\n",
    "    )\n",
    "\n",
    "\n",
    "    pos_weights = y * pos_weights.unsqueeze(0)\n",
    "    neg_weights = (1 - y) * neg_weights.unsqueeze(0)\n",
    "    all_weights = pos_weights + neg_weights\n",
    "    loss *= all_weights\n",
    "    norm = torch.sum(all_weights, dim=1).unsqueeze(1)\n",
    "    loss /= norm\n",
    "    loss = torch.sum(loss, dim=1)\n",
    "\n",
    "\n",
    "    if verbose:\n",
    "        print('loss', loss)\n",
    "        print('all weights', all_weights)\n",
    "        print('weighted loss', loss)\n",
    "        print('normalization factors', norm)\n",
    "        print('normalized loss', loss)\n",
    "        print('summed up over patient_overall-C1-C7 loss', loss)\n",
    "\n",
    "    if reduction == 'mean':\n",
    "        return torch.mean(loss)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f1f858",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-03T12:11:30.859065Z",
     "iopub.status.busy": "2022-09-03T12:11:30.858724Z",
     "iopub.status.idle": "2022-09-03T12:11:32.547340Z",
     "shell.execute_reply": "2022-09-03T12:11:32.546279Z"
    },
    "papermill": {
     "duration": 1.715864,
     "end_time": "2022-09-03T12:11:32.549440",
     "exception": false,
     "start_time": "2022-09-03T12:11:30.833576",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Quick test of  patient_overall + C1-C7 loss\n",
    "weighted_loss(\n",
    "    torch.logit(torch.tensor([\n",
    "        [0.1, 0.9, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1],\n",
    "        [0.1, 0.9, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]\n",
    "    ])).to(DEVICE),\n",
    "    torch.tensor([\n",
    "        [1., 1., 0., 0., 0., 0., 0., 0.],\n",
    "        [0., 0, 0., 0., 0., 0., 0., 0.]\n",
    "    ]).to(DEVICE),\n",
    "    reduction=None,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3db0cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-03T12:11:32.584507Z",
     "iopub.status.busy": "2022-09-03T12:11:32.583080Z",
     "iopub.status.idle": "2022-09-03T12:11:32.600361Z",
     "shell.execute_reply": "2022-09-03T12:11:32.598834Z"
    },
    "papermill": {
     "duration": 0.036993,
     "end_time": "2022-09-03T12:11:32.603084",
     "exception": false,
     "start_time": "2022-09-03T12:11:32.566091",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Quick test of C1-C7 loss\n",
    "weighted_loss(\n",
    "    torch.logit(torch.tensor([\n",
    "        [0.9, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1],\n",
    "        [0.9, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]\n",
    "    ])).to(DEVICE),\n",
    "    torch.tensor([\n",
    "        [1., 0., 0., 0., 0., 0., 0.],\n",
    "        [0, 0., 0., 0., 0., 0., 0.]\n",
    "    ]).to(DEVICE),\n",
    "    reduction=None,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da095686",
   "metadata": {
    "papermill": {
     "duration": 0.016856,
     "end_time": "2022-09-03T12:11:32.636854",
     "exception": false,
     "start_time": "2022-09-03T12:11:32.619998",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-success\" style=\"font-size:25px\">\n",
    "    ü¶¥ 5.2 Train: training/evaluation loop ü¶¥\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e8b0e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-03T12:11:32.670617Z",
     "iopub.status.busy": "2022-09-03T12:11:32.670312Z",
     "iopub.status.idle": "2022-09-03T12:11:32.675174Z",
     "shell.execute_reply": "2022-09-03T12:11:32.674110Z"
    },
    "papermill": {
     "duration": 0.024045,
     "end_time": "2022-09-03T12:11:32.677463",
     "exception": false,
     "start_time": "2022-09-03T12:11:32.653418",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def filter_nones(b):\n",
    "    return torch.utils.data.default_collate([v for v in b if v is not None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544316fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-03T12:11:32.711892Z",
     "iopub.status.busy": "2022-09-03T12:11:32.710317Z",
     "iopub.status.idle": "2022-09-03T12:11:32.715409Z",
     "shell.execute_reply": "2022-09-03T12:11:32.714545Z"
    },
    "papermill": {
     "duration": 0.023835,
     "end_time": "2022-09-03T12:11:32.717366",
     "exception": false,
     "start_time": "2022-09-03T12:11:32.693531",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_model(name, model):\n",
    "    torch.save(model.state_dict(), f'{name}.tph')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90be1a2a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-03T12:11:32.752452Z",
     "iopub.status.busy": "2022-09-03T12:11:32.750752Z",
     "iopub.status.idle": "2022-09-03T12:11:32.760828Z",
     "shell.execute_reply": "2022-09-03T12:11:32.759952Z"
    },
    "papermill": {
     "duration": 0.029261,
     "end_time": "2022-09-03T12:11:32.762997",
     "exception": false,
     "start_time": "2022-09-03T12:11:32.733736",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_model(model, name, path='.'):\n",
    "    data = torch.load(os.path.join(path, f'{name}.tph'), map_location=DEVICE)\n",
    "    model.load_state_dict(data)\n",
    "    return model\n",
    "\n",
    "\n",
    "# quick test\n",
    "model = torch.nn.Linear(2, 1)\n",
    "save_model('testmodel', model)\n",
    "\n",
    "model1 = load_model(torch.nn.Linear(2, 1), 'testmodel')\n",
    "assert torch.all(\n",
    "    next(iter(model1.parameters())) == next(iter(model.parameters()))\n",
    ").item(), \"Loading/saving is inconsistent!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6d060b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-03T12:11:32.798100Z",
     "iopub.status.busy": "2022-09-03T12:11:32.797184Z",
     "iopub.status.idle": "2022-09-03T12:11:38.017458Z",
     "shell.execute_reply": "2022-09-03T12:11:38.016209Z"
    },
    "papermill": {
     "duration": 5.241076,
     "end_time": "2022-09-03T12:11:38.020695",
     "exception": false,
     "start_time": "2022-09-03T12:11:32.779619",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_effnet(model: EffnetModel, ds, max_batches=PREDICT_MAX_BATCHES, shuffle=False):\n",
    "    torch.manual_seed(42)\n",
    "    model = model.to(DEVICE)\n",
    "    dl_test = torch.utils.data.DataLoader(ds, batch_size=BATCH_SIZE, shuffle=shuffle, num_workers=os.cpu_count(),\n",
    "                                          collate_fn=filter_nones)\n",
    "    pred_frac = []\n",
    "    pred_vert = []\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        frac_losses = []\n",
    "        vert_losses = []\n",
    "        with tqdm(dl_test, desc='Eval', miniters=10) as progress:\n",
    "            for i, (X, y_frac, y_vert) in enumerate(progress):\n",
    "                with autocast():\n",
    "                    y_frac_pred, y_vert_pred = model.forward(X.to(DEVICE))\n",
    "                    frac_loss = weighted_loss(y_frac_pred, y_frac.to(DEVICE)).item()\n",
    "                    vert_loss = torch.nn.functional.binary_cross_entropy_with_logits(y_vert_pred, y_vert.to(DEVICE)).item()\n",
    "                    pred_frac.append(torch.sigmoid(y_frac_pred))\n",
    "                    pred_vert.append(torch.sigmoid(y_vert_pred))\n",
    "                    frac_losses.append(frac_loss)\n",
    "                    vert_losses.append(vert_loss)\n",
    "\n",
    "                if i >= max_batches:\n",
    "                    break\n",
    "        return np.mean(frac_losses), np.mean(vert_losses), torch.concat(pred_frac).cpu().numpy(), torch.concat(pred_vert).cpu().numpy()\n",
    "\n",
    "# quick test\n",
    "m = EffnetModel()\n",
    "frac_loss, vert_loss, pred1, pred2 = evaluate_effnet(m, ds_train, max_batches=2)\n",
    "frac_loss, vert_loss, pred1.shape, pred2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa59f2e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-03T12:11:38.096780Z",
     "iopub.status.busy": "2022-09-03T12:11:38.096260Z",
     "iopub.status.idle": "2022-09-03T12:11:38.103310Z",
     "shell.execute_reply": "2022-09-03T12:11:38.102283Z"
    },
    "papermill": {
     "duration": 0.049915,
     "end_time": "2022-09-03T12:11:38.108163",
     "exception": false,
     "start_time": "2022-09-03T12:11:38.058248",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def gc_collect():\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c915e4a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-03T12:11:38.183354Z",
     "iopub.status.busy": "2022-09-03T12:11:38.182859Z",
     "iopub.status.idle": "2022-09-03T12:11:51.022411Z",
     "shell.execute_reply": "2022-09-03T12:11:51.021393Z"
    },
    "papermill": {
     "duration": 12.880236,
     "end_time": "2022-09-03T12:11:51.025193",
     "exception": false,
     "start_time": "2022-09-03T12:11:38.144957",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %%wandb\n",
    "# inline wandb diagrams!\n",
    "import wandb\n",
    "\n",
    "def train_effnet(ds_train, ds_eval, logger, name):\n",
    "    torch.manual_seed(42)\n",
    "    dl_train = torch.utils.data.DataLoader(ds_train, batch_size=BATCH_SIZE, shuffle=True, num_workers=os.cpu_count(),\n",
    "                                           collate_fn=filter_nones)\n",
    "\n",
    "    model = EffnetModel().to(DEVICE)\n",
    "    optim = torch.optim.Adam(model.parameters())\n",
    "    scheduler = torch.optim.lr_scheduler.OneCycleLR(optim, max_lr=ONE_CYCLE_MAX_LR, epochs=1,\n",
    "                                                    steps_per_epoch=min(EFFNET_MAX_TRAIN_BATCHES, len(dl_train)),\n",
    "                                                    pct_start=ONE_CYCLE_PCT_START)\n",
    "\n",
    "    model.train()\n",
    "    scaler = GradScaler()\n",
    "    with tqdm(dl_train, desc='Train', miniters=10) as progress:\n",
    "        for batch_idx, (X, y_frac, y_vert) in enumerate(progress):\n",
    "\n",
    "            if ds_eval is not None and batch_idx % SAVE_CHECKPOINT_EVERY_STEP == 0 and EFFNET_MAX_EVAL_BATCHES > 0:\n",
    "                frac_loss, vert_loss = evaluate_effnet(\n",
    "                    model, ds_eval, max_batches=EFFNET_MAX_EVAL_BATCHES, shuffle=True)[:2]\n",
    "                model.train()\n",
    "                logger.log(\n",
    "                    {'eval_frac_loss': frac_loss, 'eval_vert_loss': vert_loss, 'eval_loss': frac_loss + vert_loss})\n",
    "                if batch_idx > 0:  # don't save untrained model\n",
    "                    save_model(name, model)\n",
    "\n",
    "            if batch_idx >= EFFNET_MAX_TRAIN_BATCHES:\n",
    "                break\n",
    "\n",
    "            optim.zero_grad()\n",
    "            # Using mixed precision training\n",
    "            with autocast():\n",
    "                y_frac_pred, y_vert_pred = model.forward(X.to(DEVICE))\n",
    "                frac_loss = weighted_loss(y_frac_pred, y_frac.to(DEVICE))\n",
    "                vert_loss = torch.nn.functional.binary_cross_entropy_with_logits(y_vert_pred, y_vert.to(DEVICE))\n",
    "                loss = FRAC_LOSS_WEIGHT * frac_loss + vert_loss\n",
    "\n",
    "                if np.isinf(loss.item()) or np.isnan(loss.item()):\n",
    "                    print(f'Bad loss, skipping the batch {batch_idx}')\n",
    "                    del loss, frac_loss, vert_loss, y_frac_pred, y_vert_pred\n",
    "                    gc_collect()\n",
    "                    continue\n",
    "\n",
    "            # scaler is needed to prevent \"gradient underflow\"\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optim)\n",
    "            scaler.update()\n",
    "            scheduler.step()\n",
    "\n",
    "            progress.set_description(f'Train loss: {loss.item() :.02f}')\n",
    "            logger.log({'loss': (loss.item()), 'frac_loss': frac_loss.item(), 'vert_loss': vert_loss.item(),\n",
    "                        'lr': scheduler.get_last_lr()[0]})\n",
    "\n",
    "    save_model(name, model)\n",
    "    return model\n",
    "\n",
    "\n",
    "# N-fold models. Can be used to estimate accurate CV score and in ensembled submissions.\n",
    "effnet_models = []\n",
    "for fold in range(N_FOLDS):\n",
    "    if os.path.exists(os.path.join(EFFNET_CHECKPOINTS_PATH, f'effnetv2-f{fold}.tph')):\n",
    "        print(f'Found cached version of effnetv2-f{fold}')\n",
    "        effnet_models.append(load_model(EffnetModel(), f'effnetv2-f{fold}', EFFNET_CHECKPOINTS_PATH))\n",
    "    else:\n",
    "        with wandb.init(project='RSNA-2022', name=f'EffNet-v2-fold{fold}') as run:\n",
    "            gc_collect()\n",
    "            ds_train = EffnetDataSet(df_train.query('split != @fold'), TRAIN_IMAGES_PATH, WEIGHTS.transforms())\n",
    "            ds_eval = EffnetDataSet(df_train.query('split == @fold'), TRAIN_IMAGES_PATH, WEIGHTS.transforms())\n",
    "            effnet_models.append(train_effnet(ds_train, ds_eval, run, f'effnetv2-f{fold}'))\n",
    "\n",
    "# \"Main\" model that uses all folds data. Can be used in single-model submissions.\n",
    "if os.path.exists(os.path.join(EFFNET_CHECKPOINTS_PATH, f'effnetv2.tph')):\n",
    "    print(f'Found cached version of effnetv2')\n",
    "    effnet_models.append(load_model(EffnetModel(), f'effnetv2', EFFNET_CHECKPOINTS_PATH))\n",
    "else:\n",
    "    with wandb.init(project='RSNA-2022', name=f'EffNet-v2') as run:\n",
    "        gc_collect()\n",
    "        ds_train = EffnetDataSet(df_train, TRAIN_IMAGES_PATH, WEIGHTS.transforms())\n",
    "        train_effnet(ds_train, None, run, f'effnetv2')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6479b9d",
   "metadata": {
    "papermill": {
     "duration": 0.016387,
     "end_time": "2022-09-03T12:11:51.059926",
     "exception": false,
     "start_time": "2022-09-03T12:11:51.043539",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<img src=\"https://images2.imgbox.com/29/19/ncuwno2X_o.png\" alt=\"image host\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd942e46",
   "metadata": {
    "papermill": {
     "duration": 0.016142,
     "end_time": "2022-09-03T12:11:51.092528",
     "exception": false,
     "start_time": "2022-09-03T12:11:51.076386",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-success\" style=\"font-size:25px\">\n",
    "    ü¶¥ 6. Evaluation ü¶¥\n",
    "</div>\n",
    "\n",
    "We cross-validate our final model here using 5 folds.\n",
    "1. We generate prediction for every holdout set for every fold.\n",
    "2. Predictions are aggregated using the non-parametric model.\n",
    "3. Final results are produced using the `weighted_loss`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f4aa06",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-03T12:11:51.127702Z",
     "iopub.status.busy": "2022-09-03T12:11:51.127123Z",
     "iopub.status.idle": "2022-09-03T12:11:57.044309Z",
     "shell.execute_reply": "2022-09-03T12:11:57.043272Z"
    },
    "papermill": {
     "duration": 5.937641,
     "end_time": "2022-09-03T12:11:57.046812",
     "exception": false,
     "start_time": "2022-09-03T12:11:51.109171",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "effnet_models = []\n",
    "for name in tqdm(range(N_FOLDS)):\n",
    "    effnet_models.append(load_model(EffnetModel(), f'effnetv2-f{name}', EFFNET_CHECKPOINTS_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3357cb64",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-03T12:11:57.085601Z",
     "iopub.status.busy": "2022-09-03T12:11:57.085300Z",
     "iopub.status.idle": "2022-09-03T12:11:57.095272Z",
     "shell.execute_reply": "2022-09-03T12:11:57.094347Z"
    },
    "papermill": {
     "duration": 0.031547,
     "end_time": "2022-09-03T12:11:57.097308",
     "exception": false,
     "start_time": "2022-09-03T12:11:57.065761",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def gen_effnet_predictions(effnet_models, df_train):\n",
    "    if os.path.exists(os.path.join(EFFNET_CHECKPOINTS_PATH, 'train_predictions.csv')):\n",
    "        print('Found cached version of train_predictions.csv')\n",
    "        df_train_predictions = pd.read_csv(os.path.join(EFFNET_CHECKPOINTS_PATH, 'train_predictions.csv'))\n",
    "    else:\n",
    "        df_train_predictions = []\n",
    "        with tqdm(enumerate(effnet_models), total=len(effnet_models), desc='Folds') as progress:\n",
    "            for fold, effnet_model in progress:\n",
    "                ds_eval = EffnetDataSet(df_train.query('split == @fold'), TRAIN_IMAGES_PATH, WEIGHTS.transforms())\n",
    "\n",
    "                frac_loss, vert_loss, effnet_pred_frac, effnet_pred_vert = evaluate_effnet(effnet_model, ds_eval, PREDICT_MAX_BATCHES)\n",
    "                progress.set_description(f'Fold score:{frac_loss:.02f}')\n",
    "                df_effnet_pred = pd.DataFrame(data=np.concatenate([effnet_pred_frac, effnet_pred_vert], axis=1),\n",
    "                                              columns=[f'C{i}_effnet_frac' for i in range(1, 8)] +\n",
    "                                                      [f'C{i}_effnet_vert' for i in range(1, 8)])\n",
    "\n",
    "                df = pd.concat(\n",
    "                    [df_train.query('split == @fold').head(len(df_effnet_pred)).reset_index(drop=True), df_effnet_pred],\n",
    "                    axis=1\n",
    "                ).sort_values(['StudyInstanceUID', 'Slice'])\n",
    "                df_train_predictions.append(df)\n",
    "        df_train_predictions = pd.concat(df_train_predictions)\n",
    "    return df_train_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04158399",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-03T12:11:57.132613Z",
     "iopub.status.busy": "2022-09-03T12:11:57.132320Z",
     "iopub.status.idle": "2022-09-03T12:12:12.179235Z",
     "shell.execute_reply": "2022-09-03T12:12:12.178162Z"
    },
    "papermill": {
     "duration": 15.066749,
     "end_time": "2022-09-03T12:12:12.181464",
     "exception": false,
     "start_time": "2022-09-03T12:11:57.114715",
     "status": "completed"
    },
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_pred = gen_effnet_predictions(effnet_models, df_train)\n",
    "df_pred.to_csv('train_predictions.csv', index=False)\n",
    "df_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e00823",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-03T12:12:12.219325Z",
     "iopub.status.busy": "2022-09-03T12:12:12.218998Z",
     "iopub.status.idle": "2022-09-03T12:12:12.790283Z",
     "shell.execute_reply": "2022-09-03T12:12:12.789266Z"
    },
    "papermill": {
     "duration": 0.59283,
     "end_time": "2022-09-03T12:12:12.793264",
     "exception": false,
     "start_time": "2022-09-03T12:12:12.200434",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_sample_patient(df_pred):\n",
    "    patient = np.random.choice(df_pred.StudyInstanceUID)\n",
    "    df = df_pred.query('StudyInstanceUID == @patient').reset_index()\n",
    "\n",
    "    plt.subplot(1, 3, 1).plot((df[[f'C{i}_fracture' for i in range(1, 8)]].values * df[[f'C{i}' for i in range(1, 8)]].values))\n",
    "    f'Patient {patient}, fractures'\n",
    "\n",
    "    df[[f'C{i}_effnet_frac' for i in range(1, 8)]].plot(\n",
    "        title=f'Patient {patient}, fracture prediction',\n",
    "        ax=(plt.subplot(1, 3, 2)))\n",
    "\n",
    "    df[[f'C{i}_effnet_vert' for i in range(1, 8)]].plot(\n",
    "        title=f'Patient {patient}, vertebrae prediction',\n",
    "        ax=plt.subplot(1, 3, 3)\n",
    "    )\n",
    "\n",
    "plot_sample_patient(df_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3706d09e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-03T12:12:12.834433Z",
     "iopub.status.busy": "2022-09-03T12:12:12.833366Z",
     "iopub.status.idle": "2022-09-03T12:12:13.357133Z",
     "shell.execute_reply": "2022-09-03T12:12:13.356216Z"
    },
    "papermill": {
     "duration": 0.546207,
     "end_time": "2022-09-03T12:12:13.359250",
     "exception": false,
     "start_time": "2022-09-03T12:12:12.813043",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_sample_patient(df_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40468f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-03T12:12:13.404050Z",
     "iopub.status.busy": "2022-09-03T12:12:13.403262Z",
     "iopub.status.idle": "2022-09-03T12:12:13.952414Z",
     "shell.execute_reply": "2022-09-03T12:12:13.951472Z"
    },
    "papermill": {
     "duration": 0.574553,
     "end_time": "2022-09-03T12:12:13.955477",
     "exception": false,
     "start_time": "2022-09-03T12:12:13.380924",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_sample_patient(df_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831795c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-03T12:12:14.002809Z",
     "iopub.status.busy": "2022-09-03T12:12:14.002492Z",
     "iopub.status.idle": "2022-09-03T12:12:16.506089Z",
     "shell.execute_reply": "2022-09-03T12:12:16.505089Z"
    },
    "papermill": {
     "duration": 2.529728,
     "end_time": "2022-09-03T12:12:16.508580",
     "exception": false,
     "start_time": "2022-09-03T12:12:13.978852",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_cols = ['patient_overall'] + [f'C{i}_fracture' for i in range(1, 8)]\n",
    "frac_cols = [f'C{i}_effnet_frac' for i in range(1, 8)]\n",
    "vert_cols = [f'C{i}_effnet_vert' for i in range(1, 8)]\n",
    "\n",
    "\n",
    "def patient_prediction(df):\n",
    "    c1c7 = np.average(df[frac_cols].values, axis=0, weights=df[vert_cols].values)\n",
    "    pred_patient_overall = 1 - np.prod(1 - c1c7)\n",
    "    return np.concatenate([[pred_patient_overall], c1c7])\n",
    "\n",
    "df_patient_pred = df_pred.groupby('StudyInstanceUID').apply(lambda df: patient_prediction(df)).to_frame('pred').join(df_pred.groupby('StudyInstanceUID')[target_cols].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee92141",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-03T12:12:16.556908Z",
     "iopub.status.busy": "2022-09-03T12:12:16.555277Z",
     "iopub.status.idle": "2022-09-03T12:12:16.579961Z",
     "shell.execute_reply": "2022-09-03T12:12:16.578963Z"
    },
    "papermill": {
     "duration": 0.049991,
     "end_time": "2022-09-03T12:12:16.581958",
     "exception": false,
     "start_time": "2022-09-03T12:12:16.531967",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_patient_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a875546d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-03T12:12:16.629269Z",
     "iopub.status.busy": "2022-09-03T12:12:16.628970Z",
     "iopub.status.idle": "2022-09-03T12:12:16.639269Z",
     "shell.execute_reply": "2022-09-03T12:12:16.638243Z"
    },
    "papermill": {
     "duration": 0.035821,
     "end_time": "2022-09-03T12:12:16.641456",
     "exception": false,
     "start_time": "2022-09-03T12:12:16.605635",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions = np.stack(df_patient_pred.pred.values.tolist())\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a9fd73",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-03T12:12:16.688566Z",
     "iopub.status.busy": "2022-09-03T12:12:16.688275Z",
     "iopub.status.idle": "2022-09-03T12:12:16.695683Z",
     "shell.execute_reply": "2022-09-03T12:12:16.694766Z"
    },
    "papermill": {
     "duration": 0.032868,
     "end_time": "2022-09-03T12:12:16.697663",
     "exception": false,
     "start_time": "2022-09-03T12:12:16.664795",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "targets = df_patient_pred[target_cols].values\n",
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60dff7f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-03T12:12:16.745257Z",
     "iopub.status.busy": "2022-09-03T12:12:16.744471Z",
     "iopub.status.idle": "2022-09-03T12:12:16.752937Z",
     "shell.execute_reply": "2022-09-03T12:12:16.751547Z"
    },
    "papermill": {
     "duration": 0.034683,
     "end_time": "2022-09-03T12:12:16.755031",
     "exception": false,
     "start_time": "2022-09-03T12:12:16.720348",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('CV score:', weighted_loss(torch.logit(torch.as_tensor(predictions)).to(DEVICE), torch.as_tensor(targets).to(DEVICE)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6296c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-20T13:17:18.762083Z",
     "iopub.status.busy": "2022-08-20T13:17:18.761536Z",
     "iopub.status.idle": "2022-08-20T13:17:18.769930Z",
     "shell.execute_reply": "2022-08-20T13:17:18.768312Z",
     "shell.execute_reply.started": "2022-08-20T13:17:18.762038Z"
    },
    "papermill": {
     "duration": 0.022738,
     "end_time": "2022-09-03T12:12:16.800328",
     "exception": false,
     "start_time": "2022-09-03T12:12:16.777590",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-danger\" style=\"text-align:center; font-size:20px;\">\n",
    "    ‚ù§Ô∏è Dont forget to ‚ñ≤upvote‚ñ≤ if you find this notebook usefull!  ‚ù§Ô∏è\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('kaggle')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 144.86591,
   "end_time": "2022-09-03T12:12:18.146193",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-09-03T12:09:53.280283",
   "version": "2.3.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "474c4e9109b6080d79a1a4975c56b0aa182258f6e73f7e638932e26e12ce92f3"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "09d6181d80e747e6a7c64d07220e1b3d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "0b0cc52846ac47e9b4f3ec744f9b4b92": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_631eda05a7c340f3a589f40c4852792b",
       "max": 5,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_53e19071d6364100b0a6455934aad9f9",
       "value": 5
      }
     },
     "1990280f0c09480c8d32e0b526094334": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_963cb1a01ef94607ab14b0135ad11c0b",
        "IPY_MODEL_0b0cc52846ac47e9b4f3ec744f9b4b92",
        "IPY_MODEL_50f64f250ba64208b6aaab418491f19c"
       ],
       "layout": "IPY_MODEL_a80d3634026e483787142671ee64b533"
      }
     },
     "1d0001a31f204cd1a894f8758e67e8e1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_2c4a8d74d222434fb116609598e2f0c1",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_d3b33bd7fb9a4df4ae62d3b2caa7a42f",
       "value": " 2/22235 [00:04&lt;13:27:13,  2.18s/it]"
      }
     },
     "24def5c6163449a3b5e198f8e5bcdee6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2c4a8d74d222434fb116609598e2f0c1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "34728ada44a646a08ce181b4140e80ca": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "3591043ecc7542b9a2c1c0418cfb251a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "50f64f250ba64208b6aaab418491f19c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_24def5c6163449a3b5e198f8e5bcdee6",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_09d6181d80e747e6a7c64d07220e1b3d",
       "value": " 5/5 [00:05&lt;00:00,  1.18s/it]"
      }
     },
     "53e19071d6364100b0a6455934aad9f9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "631eda05a7c340f3a589f40c4852792b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7067fbff29754b36930fef6a24ff2428": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_a1e705de9f234ac6af18a30a72e8c43b",
        "IPY_MODEL_f8d5726c0eaf4311b3fe56b3b4e35e39",
        "IPY_MODEL_1d0001a31f204cd1a894f8758e67e8e1"
       ],
       "layout": "IPY_MODEL_3591043ecc7542b9a2c1c0418cfb251a"
      }
     },
     "788de582b09a43a6aa0050c8dce4cc1c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "8c115480c443447aa64d1163a88bea19": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "963cb1a01ef94607ab14b0135ad11c0b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_ff849ff799fa4103b85e5339b446efc4",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_788de582b09a43a6aa0050c8dce4cc1c",
       "value": "100%"
      }
     },
     "a1e705de9f234ac6af18a30a72e8c43b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_8c115480c443447aa64d1163a88bea19",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_34728ada44a646a08ce181b4140e80ca",
       "value": "Eval:   0%"
      }
     },
     "a80d3634026e483787142671ee64b533": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "bc2e7c17140e402aa7dfb76bf847be2b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c8d3b71b6e004aee84d387ede41c33c4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "d3b33bd7fb9a4df4ae62d3b2caa7a42f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "f8d5726c0eaf4311b3fe56b3b4e35e39": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "danger",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_bc2e7c17140e402aa7dfb76bf847be2b",
       "max": 22235,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_c8d3b71b6e004aee84d387ede41c33c4",
       "value": 2
      }
     },
     "ff849ff799fa4103b85e5339b446efc4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
